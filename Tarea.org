   - CSS :: Cascading Style Sheets is used to give more life to your
            page, since HTML gives us black letters in white
            background, again, in a /barebones/ setup, using CSS is
            needed to improve your page.

	    With CSS, you can change the looks of your page, maybe
            different fonts, a different background color.

   - PHP :: Hypertext PreProcessor is made to make our page more
            'dinamic', by creating scripts that will be executed in
            the server side.

	    With PHP, you can administer your page better and control
            it in a more 'modular' way, or execute scripts needed for
            the page workings, without the client knowing they are
            being executed.

   - JavaScript :: Scripts that will be run on the client side, allows
                   us to make good interactions with the client.

		   It's normally used to make better interactions with
                   the client, or the looks of something on our page.

   - MySQL :: A Database, allowing us to better control and managing
              of information of our webpage.

   This all depends of the page you want, you can have a simple
   webpage with just Apache, HTML and CSS, or add only PHP, or only
   MySQL, it depends

*** Apache                                                  :Apache:Servidor:

 - Apache :: HTTP +WEB+ Server, Permite acceso a nuestra
             página. Utilizando Hostnames, es acceso a nuestra página
             refiriendonos a un nombre.

  - Clientes, servidores y URLs :: Cuando nos queremos conectar a una
       página, ponemos algo así como: https: -//- www. - gnu.org. Esto
       contiene diferentes elementos, en el siguiente orden:

    - El protocolo :: Nos referimos a la parte 'http' o 'https' de una
                      página, el protocolo que utiliza la página para
                      enviarle archivos a su cliente.

                      El protocolo no son más que reglas que deben de seguir las
                      dos partes para una comunicación eficaz.

 - Hostnames :: Los hostnames, o nombres de host, se refieren a el
               nombre de una página, la cual esta estrictamente
               relacionado con donde reside la página en el
               internet. Y por estos nombres es la razón por la que no
               debemos de referirnos a un servidor por su ip,
               imaginate referirse a 123.423.12.13/32 (es un ejemplo),
               para conectarse a cualquier página. Para evitar este
               problema, se utilizan los nombres de host.

 - HTTP :: HyperText Transfer Protocol, protocolo de transferencia de
           hiper textos. hiper textos se refiere a los archivos que utiliza la
           pagina para darle una imágen a la página web, la más utilizada
           vendría a ser el lenguaje de marcado 'HTML'.

           El lenguaje de marcado HTML es necesario para dar una estructura a la
           página, sin embargo, no le da un buen 'diseño', por ende, es
           utilizado junto a PHP, para generar contenido dinámico, Javascript,
           para generar mejor visión e interacción con el usuario, CSS, más
           cercano a HTML para generar reglas de vista para elementos, y quizá
           MySQL, para un mejor guardado y manejado de archivos.

           Claro que cualquiera de estos elementos es opcional, sin embargo, se
           han convertido en muy importantes a la hora de hacer un p+agina web,
           ya que se pueden hacer distintas cosas con ellos.

           Luego de esta explicación, es bastante sencillo ver que, al yo entrar
           a una página web, le digo a el servidor: quiero un archivo.

           Dicho archivo puede ser por lo general un HTML, tambien puede ser
           otro como expliqué antes.
           
           El servidor escucha nuestra respuesta y nos envía el archivo, lo
           recibimos y nuestro navegador hace el trabajo de 'traducir' el
           archivo, y mostrarnos la página web. Y con eso, la interacción esta
           completa.
           
*** PHP                                                                 :PHP:
    
 - PHP :: *Lenguaje de Guión* mundialmente usado en el diseño de
          páginas web, debido a su capacidad de unirse en el código de
          HTML de forma perfecta. 

 - Lenguaje de Guión :: Lenguaje especializado en la ejecución de
      guiones, o scripts, los cuales a su vez, contienen diferentes
      comandos que deberá ejecutar dicho lenguaje de guión.

 - HTML, PHP, relación :: PHP puede realizar todo lo que un programa
      CGI puede hacer, puede ejecutar scripts de el lado de el
      servidor, y mostrar solo el resultado, unido con HTML, se pueden
      hacer cosas bastante interesantes en una página web, por ende su
      unión y su necesidad en una página web.

 - Plantilla PHP :: En PHP se pueden trabajar con plantillas, que no
                    son más que nada un "cuerpo" básico de una página
                    web, el que uno puede modificar como desee. No hay
                    mucha diferencia en uno escribir la plantilla uno
                    mismo, solo que al copiarla, se da tiempo (esta
                    solo debe ser copiada si se entiende cada uno de
                    los elementos), Al ser una plantilla, podemos
                    añadirle lo que deseemos, tanto más funcionamiento
                    con PHP, como contenido con HTML, como diseño con CSS.

 - Include y Require :: Dos comandos muy utilizados en PHP, sirven para
      incluir archivos externos de PHP, muy útil a la hora de añadir
      alguna función que desees pero que esté en otro archivo. Por lo
      general, es utilizado a la hora de hacer páginas web, para poder
      dividir sus elementos en diferetnes archivos, los cuales pueden
      estar mejor organizados, es una gran manera de hacer una página
      web.

      Como dicho anteriormente, PHP puede 'embeberse' en HTML, así podiendo crear
      un servidor el cual mandará resultados a el usuario de scripts, pero no
      enviará el script en sí.

      Como en todo lenguaje, existen diferentes variables predeterminadas en PHP,
      las cuales darán funciones necesarias a nuestro script, a parte, cada
      variable de PHP debe de ser referenciada con un '$' al principio para
      indicar que es una variable.

      De manera resumida, las cosas que PHP puede hacer son:
     
   - Generación de contenido de página dinámico

   - Creación, apertura, lectura, escritura, borrad y ierre de archivos en el servidor

   - Recolección de datos en formularios

   - Inserción, borrado y modificación de información almacenada en tu base de datos
o
   - Control de acceso de usuarios

   - Encriptamiento de datos

     Para comenzar codigo en PHP, se debe comenza con etiquetas que le indicarán
     a el servidor que se ejecutará PHP, todo el código de PHP debe ir dentro
     de : <?php ... ?>.

     Como alternativa, podemos inluir PHP con la etiqueta <script> de HTML, algo
     parecido a: <script language="php">  ... </script>.

     Se pueden utilizar las etiquetas PHP abreviadas, <? ... ?>, siempre y
     cuando estén soportadas por el servidor.

     PHP tiene una función "echo" predefinida, la cual es utilizada para dar
     salida al texto. Más específicamente, no es una función, más un constructor
     del lenguaje. Como tal, no requiere paréntesis.

     #+BEGIN_SRC php

     <?php
       echo "PHP"!;
     ?>
 
     #+END_SRC

     Cada código de PHP, o cada declaración debe de termina con un punto y coma.

     Las etiquetas de HTML pueden ser añadidas al texto en la declaración echo.

     #+BEGIN_SRC php

     <?php 
        echo "<strong> BOLD </strong>";
     ?>

     #+END_SRC
     
     Los comentarios de PHP son de una línea, que comienzan por '//', y de
     varias líneas, que comienzan y terminan por "/*" "*/"

     Existen reglas para las variables de PHP:

     - Un nombre de variable debe comenzar con una letra o un guión bajo

     - UN nombre de variable no puede comenzar con un número

     - Un nombre de variable solo puede contener carácteres alfanuméricos y
       guiones bajos

     - Los nombre de variables son sensibles a mayúsculas.

       Existen diferentes tipos de variables en PHP, las más comúnes viniendo a
       ser string, boolean, bloat e integer, sin embargo, algo interesante de
       PHP, es ue PHP automáticamente convierte a la variable al tipo de dato
       correcto, dependiendo su valor.

       Por ejemplo, en otros lenguajes, a la hora de intentar 'imprimir' o
       mostrar un variable, solo se pueden con variables strings, de lo
       contrario, habría que convertirlo, o es un error, esto no aplica en PHP
       ya que convierte automáticamente la variable a el tipo necesario.

       

*** MySQL                                                             :MySQL:

- MySQL :: Es un sistema de mantenimiento de datos… Pueden ser tanto
           archivos simples, como fotos, video, etc. Pero cuando
           hablamos a un nivel corporativo, como, GNU, estamos
           hablando a que la cantidad de información es exorbitante,
           haciendo que MySQL entre en juego, para manejar la
           información de una manera más sencilla, que haga el trabajo de
           mantener la información 'aguantable'.

- MariaDB, MySQL, relación :: Realmente, no tienen relación alguna más
     que de competidores, MariaDB podría considerarse una alternativa
     a MySQL con más características, pero, MySQL es la más
     utilizada. Pero MariaDB planea quitarle ese puesto claro.

*** Joomla                                                       :Joomla:Web:
 
 - Joomla :: Es un muy famoso CMS, sirve para crear y manejar una página web de
             manera sencilla. Tiene dos partes en las que en mi opinión,
             destaca.

   1. Módulos :: Extensiones, que le añaden funcionamiento a tu página
                 web, ya sea visible o no.

   2. Libre :: Joomla es un CMS libre, lo que quiere decir que puedes cambiar
               cada parte de el funcionamiento de Joomla, y por lo tanto, tu
               página web. Usuarios experimentados sabrán explotar esto al máximo.

   - CMS :: Content Management System. Un sistema de mantenimiento de
            contenido, como sería su traducción literal, aunque es
            mejor llamarlo: *Sistema de Administración de Sistemas*
            es un programa que nos brinda una interfaz entendible, para
            que cualquier persona, tenga conocimientos o no de
            desarrollo web, para realizar una página web.
		      
*** CSS                                                             :CSS:WEB:

 - CSS :: (Cascading Style Sheets) Es un elemento extra que se puede
          utilizar en un documento de HTML para darle más forma,
          siendo más específico, para customizar más la forma en la
          que se ve la página web, funciona mediante reglas, en las
          que uno puede definir como va a ser algo presentado. Se
          puede añadir en un documento de HTML, y es uno de los
          principales a la hora de 'mejorar' una página web.

** GNU/Linux Guix                                                      :Guix:
   
- GNU/Linux Guix :: Distribución de GNU/Linux basada en el administrador de
                    paquetes guix. Es un sistema libre.

- Guix :: Sistema de mantenimiento de paquetes puramente funcional, no
          difiere en mucho con nix, pero si tiene ciertos detalles que
          en mi opinión, le hacen mejor. Primero que nada, utiliza un
          lenguaje de programación, Guile, nix, en cambio, utiliza un
          lenguaje de programación credo por nix. Lo cual puede tener
          sus inconvenientes.

- Guix Channels :: Manera que utiliza Guix para poder añadir más
                   paquetes mediante un repositorio Git.

*** Un tutorial de como hacer paquetes en guix 

    Guix utiliza Guile como lenguaje de programación, esto le brinda la
    posibilidad de extenderse, incluso mediante el uso de funciones,
    estructuras y macros.

    Cada paquete de Guix, está previamente definido mediante una
    'definición de paquetes'. Esto se refiere a un archivo en el cual se
    define todo lo necesario para que Guix construya e instale un
    paquete. 

    Veamos un ejemplo de una definición de paquete, utilizaremos como
    ejemplo el paquete 'hello', el cual es sencillo debido a su función. E
    intentaremos crear un paquete modificado con la ayuda de el siguiente
    manual, disponible en inglés: [[https://guix.gnu.org/blog/2018/a-packaging-tutorial-for-guix/][Empaquetamiento de Guix.]]

**** Definición de el paquete 'hello'

#+BEGIN_SRC scheme guile

(define-public hello
  (package
    (name "hello")
    (version "2.10")
    (source (origin
              (method url-fetch)
              (uri (string-append "mirror://gnu/hello/hello-" version
                                  ".tar.gz"))
              (sha256
               (base32
                "0ssi1wpaf7plaswqqjwigppsg5fyh99vdlb9kzl7c9lng89ndq1i"))))
    (build-system gnu-build-system)
    (synopsis "Hello, GNU world: An example GNU package")
    (description
     "GNU Hello prints the message \"Hello, world!\" and then exits.  It
serves as an example of standard GNU coding practices.  As such, it supports
command-line arguments, multiple languages, and so on.")
    (home-page "https://www.gnu.org/software/hello/")
    (license gpl3+)))

#+END_SRC

En la definición de el paquete, se deben de definir diferentes
elementos necesarios para poder construir e instalar el paquete, en
está definición, se podrán ver elementos algo obvios, por ejemplo, el
nombre de el paquete, su descripción y su versión.

- define-public :: Define una variable pública, esto nos permite
                   referirnos a la definición por el nombre.

- name :: El nombre de el paquete, no debe de ser confundida con el
          nombre de variable con el que le es definido en
          define-public, son el mismo nombre debido a que así deben de
          ser referidos entre ellos. Sin embargo, el nombre de
          'define-public' puede ser diferente.

- version :: La version de el paquete, debe concordar con el paquete descargado.

- source :: Aquí, comenzamos a definir el lugar de descargado de el
            paquete, puede ser tanto un página web, como un
            repositorio Git, por ejemplo.

  - origin :: Definimos el origen del cual será descargado el paquete.

    - method url-fetch :: Define que el método utilizado en la
         descarga de este paquete, será mediante una página web, un URL.

  - string-append :: Aquí definimos que la página o URL por la cual
                     será descargado el paquete, utilizando el metodo
                     URL, será la unión de mirrot://gnu/hello/hello-",
                     con 'version', y la '.tar.gz'. Esto quiere decir
                     que. el URL será:
                     mirror://gnu/hello/hello-2.10.tar.gz.

  - sha256 :: Comenzaremos a definir el hash de este paquete. 

  - base32 :: Hash de el paquete, si el hash es diferente, guix no
              instalará el paquete.

  - build-system gnu-build-system :: Procedimientos por los cuales el
       paquete será instalado.

  - sinopsis :: Breve descripción de el paquete.

  - description :: Descripción extendida de el paquete, por si se
                   desea más información, o la sinopsis no fue lo
                   suficientemente clara.

  - home-page :: La página web en donde está alojada el proyecto.

  - license :: La licencia a la cual el proyecto esta sujeto.

Dando un vistazo a la definición del paquete 'hello', nos daremos
cuenta de qué es lo que necesita una definición de paquete para ser
válida para Guix. Crearemos nuestro propio paquete modificado, como
una copia de la definición original de 'hello', le llamaremos 'my-hello'.

**** Paquete my-hello

#+BEGIN_SRC scheme guile

(use-modules (guix packages)
             (guix download)
             (guix build-system gnu)
             (guix licenses))

(package
  (name "my-hello")
  (version "2.10")
  (source (origin
            (method url-fetch)
            (uri (string-append "mirror://gnu/hello/hello-" version
                                ".tar.gz"))
            (sha256
             (base32
              "0ssi1wpaf7plaswqqjwigppsg5fyh99vdlb9kzl7c9lng89ndq1i"))))
  (build-system gnu-build-system)
  (synopsis "Hello, Guix world: An example custom Guix package")
  (description
   "GNU Hello prints the message \"Hello, world!\" and then exits.  It
serves as an example of standard GNU coding practices.  As such, it supports
command-line arguments, multiple languages, and so on.")
  (home-page "https://www.gnu.org/software/hello/")
  (license gpl3+))

#+END_SRC

Debido a que el paquete está en otro directorio, se le deben de añadir
elementos necesarías para que sea una definición de paquete válida.

- use-modules :: Aquí definimos los módulos que son necesarios por el
                 paquete, la razón por la cual la definición de
                 paquete 'hello' no los tiene, es debido a que ya
                 están añadidos.

  - guix packages :: Al importar este módulo, nos da todo lo necesario
                     para un paquete de guix.

  - guix download :: Nos da la posibilidad de usar 'source'

  - guix build-system gnu :: Nos brinda la posibilidad de llamar las
       variables "build-system gnu-build-system", con los cual
       construiremos los paquetes. Existen diferentes métodos de
       construcción, por ejemplo, para la construcción de un paquete
       de emacs, o de ruby, es diferente a un paquete normal.

  - guix licenses :: Nos da la posibilidad de referirnos a las
                     licencias, por ejemplo, gpl3+ es reconocido
                     debido a este módulo. De otro modo, nos daría un
                     error de: dpl3+ unbounded variable.

Aquí no estamos utilizando *(define-public)*, debido a que por ahora
es innecesario, solo necesitamos instalar el paquete.

Luego de tener una definición de paquete válida, es necesario
verificar el HASH, ya que si este es incorrecto, Guix se rehusará a la
construcción e instalación de el paquete. Guix brinda una herramienta
que automatiza dicho trabajo.

#+BEGIN_SRC 

guix download mirror://gnu/hello/hello-2.10.tar.gz

#+END_SRC

En este comando, guix nos descargará el paquete y nos generará un
HASH, además de incluír el paquete en la tienda.

Si el hash concuerda con el contenido en nuestra definición de
paquete, no se debe de cambiar nada, de lo contrarió, si el hash
difiere (quizá debido a una versión), se deberá de cambiar por la obtenida.

Luego de verificar el Hash, y cambiarlo si es necesario, procedermos
con la instalación de el paquete.

#+BEGIN_SRC scheme guile

guix package --install-from-file=my-hello.scm ;Estándo en el directorio que contenga la definición.

#+END_SRC

/También se puede utilizar guix package -f/

Se instalará nuestro paquete, con ello, tendremos listo nuestro primer
paquete de Guix.

Hasta ahora, para instalar o referirse a nuestro paquete, es necesario
referirnos también al directorio en el cual está nuestra definición,
si se desea evitar esto, existen dos opciones.

**** Variable de Guix

Guix nos permite una variable global, en la que podemos poner un
directorio, o varios, en los cuales guix verificará definiciones de
paquetes, y será posible referirse a ellos, mediante el comando "guix
install", o "guix package -i".

La variable es "GUIX_PACKAGE_PATH", esto quiere decir, que si
tenemos un directorio en ~/Paquetes-de-Guix/, y lo ponemos en dicha
variable, cualquier definición de paquete dentro de este directorio,
podrá ser referida globalmente. Para hacer esto, podemos utilizar:

#+BEGIN_SRC bash

export GUIX_PACKAGE_PATH=~/Paquetes-de-Guix/
# Puede ser cualquier directorio, incluso dentro de documentos.
# Ahora, al verificar que tiene la variable, nos dará nuestro directorio.
# Podemos ver esto ejecutando lo siguiente:
echo $GUIX_PACKAGE_PATH

#+END_SRC

Luego de definir esta variable, deberemos de modificar un poco nuestro
paquete, y añadirle "define-public" para que pueda ser referido
públicamente. Quedará de esta manera:

#+BEGIN_SRC scheme guile

(define-module (my-hello)
  #:use-module (guix licenses)
  #:use-module (guix packages)
  #:use-module (guix build-system gnu)
  #:use-module (guix download))

(define-public my-hello
  (package
    (name "my-hello")
    (version "2.10")
    (source (origin
              (method url-fetch)
              (uri (string-append "mirror://gnu/hello/hello-" version
                                  ".tar.gz"))
              (sha256
               (base32
                "0ssi1wpaf7plaswqqjwigppsg5fyh99vdlb9kzl7c9lng89ndq1i"))))
    (build-system gnu-build-system)
    (synopsis "Hello, Guix world: An example custom Guix package")
    (description
     "GNU Hello prints the message \"Hello, world!\" and then exits.  It
serves as an example of standard GNU coding practices.  As such, it supports
command-line arguments, multiple languages, and so on.")
    (home-page "https://www.gnu.org/software/hello/")
    (license gpl3+)))

#+END_SRC

Lo único que añadimos fue "define-public", al añadir esto, ahora
podremos instalar nuestro paquete mediante "guix install my-hello", o "guix
package -i my-hello".

Con esto, podremos referirnos a el paquete públicamente, sin embargo,
no podrá ser instalada mediante 'guix package -f'. Si deseamos poder
instalarlo de esta manera, se debe de referirse a el al final de el
archivo, con su nombre público:

#+BEGIN_SRC scheme guile

; ...
(define-public my-hello
  ; ...
  )

my-hello

#+END_SRC

De esta manera, también podremos instalarlo referiendonos al archivo
directamente.

**** Utilizando Channels

Primero que nada, necesitaremos git. Para esto podremos utilizar: 

#+BEGIN_SRC bash

guix install git

#+END_SRC

Luego de instalarse, deberemos de ir al directorio que deseamos
convertir en un repositorio git local, y ejecutar:

- git init :: Esto iniciara git, y creará una carpeta oculta de git.
- git add . :: Aquí añadimos todos los archivos de el directorio, en
               este caso deberían de estar nuestras definiciones de paquetes.
- git commit :: Esto habrá añadido todos los cambios, y con esto,
                nuestro repositorio de git local esta listo.

Deberemos de crear un archivo scheme, en el cual se definirán los
channels, y podremos añadir nuestro repositorio git local. Dicho
archivo es: ~/.config/guix/channels.scm.

Dentro de este archivo, podremos añadir más un repositorio:

#+BEGIN_SRC scheme guile

  (list (channel
	 (name 'guix)
	 (url "https://example.org/my-guix.git")
	 (branch "master")))

#+END_SRC

Pero en este caso, dado que es un repositorio local, debemos de hacer
algo diferente, algo parecido a esto:

#+BEGIN_SRC scheme guile

    (list (channel
	   (name 'guix)
	   '(url "file:///home/$USER/donde-estan-tus-paquetes")
	   (branch "master")))

#+END_SRC

De esta manera, al ejecutar 'guix pull', se detectará el nuevo
channel, y al ser añadido, podremos ver nuestros paquetes
universalmente.

*** Crear y usar un Linux kernel modificado en un sistema Guix

Guix es un sistema en la que se utilizan sustitutos, estos son,
servidores a los que te puedes conectar, que te proveen de paquetes
pre-construidos, ya que, en guix es muy común al instalar un paquete
el tener que instalarlo, se debe tomar en cuenta que los sustitutos
fueron creados con el fín de no gastar tantos recursos en construir un
npaquete. Los sustitutos solo deben de ser utilizados si se confía en
el servidor, ya que una vez descargado algo de este, no se puede
confirmar de que el archivo del que te provee, es el archivo que
pediste sin modificaciones. Utilizaremos la siguiente guía: [[https://guix.gnu.org/blog/2018/a-packaging-tutorial-for-guix/][Kernel de
Linux modificado en Guix, disponible en inglés.]]

  - Definión de paquete de Linux-Libre :: Como ya sabemos de
       anteriores investigaciones, los paquetes de guix se manejan con
       definiciones de paquetes, estos pueden ser normalmente
       modificados, la definición de paquete de el kernel Linux-Libre
       no es una excepción a esto, a pesar de esto, es un tanto
       diferente, veamos que posee.

**** Definición de paquete, kernel Linux-Libre

#+BEGIN_SRC lisp
(define* (make-linux-libre version hash supported-systems
                           #:key
                           ;; A function that takes an arch and a variant.
                           ;; See kernel-config for an example.
                           (extra-version #f)
                           (configuration-file #f)
                           (defconfig "defconfig")
                           (extra-options %default-extra-linux-options)
                           (patches (list %boot-logo-patch)))
  ...)
#+END_SRC

- Maneras de modificar el paquete :: Como se puede notar, la
     definición del paquete Linux-Libre es algo diferente
     a las demás. Veamos como esta constituído este paquete. Esta
     definición de paquete es de hecho, un procedimiento que crea un
     paquete.
  - define* :: Comenzamos con la definición de una variable, para eso
	       funciona *define*, el "*" extra que podemos encontrar,
	       es único de Guile, y permite le uso de argumentos
	       únicos y opcionales.
  - make-linux-libre version hash supported systems :: Se refiere al
       nombre del paquete, siguiendo con las reglas que se ven en
       guix, significa que hay un archivo de esta manera:
       make-linux-libre/version/hash/supported-systems.
  - #key :: argumento único.
  - (extra-version #f) :: Se le añade un valor booleano de falso a
       *extra-version*
  - (configuration-file #f) :: Se le añade un valor falso a
       *configuration-file*, que se refiera el archivo .config file
       que contiene parametros con los que se va a construír el paquete.
  - (defconfig "defconfig") :: Se refiere a otro archivo de configuración.
  - extra-options %default-extra-linux-options) :: Se refiere a
       parámetros que son añadidos a la hora de construir el paquete.
  - (patches (list %boot-logo-patch)) :: Se refiere a los parches que
       son añadidos, o lo 'extra' al paquete.
***** Primera manera de modificación 
**** Declaración del paquete del kernel Linux-Libre 5.1.x

#+BEGIN_SRC lisp

(define-public linux-libre
  (make-linux-libre %linux-libre-version
                    %linux-libre-hash
                    '("x86_64-linux" "i686-linux" "armhf-linux" "aarch64-linux")
                    #:patches %linux-libre-5.1-patches
                    #:configuration-file kernel-config))

#+END_SRC

- define-public :: Define la variable y la hace pública, ahora puede
                   ser referenciada en otras partes.
- make-linux-libre %linux-libre-version :: se refiere a la definición
     anterior presentada en Linux-Libre.
- %linux-libre-hash :: Otra referencia a la anterior definición de
     linux-libre
- '("x86_64-linux" "i686-linux" "armhf-linux" "aarch64-linux") ::
     Podemos notar que todas son referiencias a la anterior definión,
     vemos que primero se refiere a la version, luego el hash, y luego
     añade las arquitecturas que son soportadas por linux, en el mismo
     orden de la anterior definición.
- #:patches %linux-libre-5.1-patches :: Parches añadidos al paquete.
- #:configuration-file kernel-config :: Se refiere al archivo .config
     utilizado.

**** Fase de configuración Linux-Libre
     
#+BEGIN_SRC lisp
  (define-public linux-libre-4.4-version "4.4.189")  
   (define-public linux-libre-4.4-pristine-source  
     (let ((version linux-libre-4.4-version)  
           (hash (base32 "0nc8v62gw89m3ykqg6nqf749fzm8y1n481ns8vny4gbinyikjhlp")))  
       (make-linux-libre-source version  
                                (%upstream-linux-source version hash)  
                                deblob-scripts-4.4)))  
#+END_SRC

Como podemos ver, aquí se están definiendo dos variables públicas, que
son exactamente lo que se necesita para la definición del paquete de
linux-libre, o lo que faltaba, la versión y el hash, ya que las
arquitecturas fueron añadidas anteriormente.

De la misma manera, se definen las configuraciones que utilizará
Linux-Libre, de esta manera:

#+BEGIN_SRC lisp
(let ((build  (assoc-ref %standard-phases 'build))
      (config (assoc-ref (or native-inputs inputs) "kconfig")))

  ;; Use a custom kernel configuration file or a default
  ;; configuration file.
  (if config
      (begin
        (copy-file config ".config")
        (chmod ".config" #o666))
      (invoke "make" ,defconfig))
#+END_SRC

- let :: es utilizado para definir varias variables en un solo
         procedimiento, aquí como vemos, se definen el modo en que se
         construirá el paquete, el archivo de configuración utilizado
         para esto, y entre otras cosas.
- build :: La variable build, es igual a *(assoc-ref %standard-phases
           'build)*.
- config :: La variable config ahora es igual a *(assoc-ref (or
            native-inputs inputs) "kconfig"))*.
- if :: Condicional.
- begin :: Comienza procedimientos.
- copy-file :: Procedimiento de copia de archivos.
- chmod :: Cambia los permisos de un archivo
- invoke :: invoca un comando, en este caso, make.

**** Ejemplo de configuración de paquete de Linux-Libre kernel

 #+BEGIN_SRC lisp
 (define-public linux-libre/E2140
   (package
     (inherit linux-libre)
     (native-inputs
      `(("kconfig" ,(local-file "E2140.config"))
       ,@(alist-delete "kconfig"
		       (package-native-inputs linux-libre))))))
 #+END_SRC

 Definiendo una variable pública de esta manera, activa la anterior
 condición anterior, lo que nos permite hacer un paquete de Linux Libre
 modificado, simplemente al añadir un .config diferentes, verifiquemos
 este ejemplo.

 - define-public :: La variable con el nombre 'linux-libre/E2140' ahora
                    puede ser referenciada públicamente, por lo que no
                    necesita estar en el mismo archivo en el que esta
                    la condición que nos permitirá ingresar un .config
                    diferente al default.
 - package :: refierete a el paquete linux-libre.
 - inherit :: obtiene el paquete linux-libre.
 - native-inputs :: Añade como native inputs, especificamente cmabiando
                    "kconfig", para que sea igual a un archivo local:
                    (local-file "E2140.config").
 - alist-delete :: Elimina "kconfig", refiriendose al anterior que
                   estaba, el kconfig default, y lo reemplaza por el nuestro.
 - package-native-inputs linux-libre :: Dice, los native inputs que
      acabo de definir, añadelos a el paquete linux-libre. Al añadir
      nuestros native-inputs a linux-libre, se activa el procedimiento
      en el que se añade nuestro .config como native input,
      reemplazando el anterior.

 ¿Qué acabos de hacer?, como vimos anteriormente, la definición de
 linux-libre es diferente a una definición normal, es una creación de
 una variable pública, entonces, lo que hicimos en todo esto fue: Crear
 una nueva variable pública agarrando todo lo que tiene el paquete de
 linux-libre, pero añadiendole ese hermoso procedimiento que se encarga
 de hacer lo que queremos.

/En el mismo archivo en el que definimos esta variable, está el/
/archivo de configuración al que nos estamos refiriendo, E2140.config/

**** Segunda manera de modificación

Otra manera de realizar una modificación este paquete, es por medio de
%default-extra-linux-options, la cual esta presente tambien en el
paquete de linux-libre

Esté es el contenido dentro de %default-extra-linux-options:

#+BEGIN_SRC lisp
(define %default-extra-linux-options
  `(;; https://lists.gnu.org/archive/html/guix-devel/2014-04/msg00039.html
   ("CONFIG_DEVPTS_MULTIPLE_INSTANCES" . #t)
   ;; Modules required for initrd:
   ("CONFIG_NET_9P" . m)
   ("CONFIG_NET_9P_VIRTIO" . m)
   ("CONFIG_VIRTIO_BLK" . m)
   ("CONFIG_VIRTIO_NET" . m)
   ("CONFIG_VIRTIO_PCI" . m)
   ("CONFIG_VIRTIO_BALLOON" . m)
   ("CONFIG_VIRTIO_MMIO" . m)
   ("CONFIG_FUSE_FS" . m)
   ("CONFIG_CIFS" . m)
   ("CONFIG_9P_FS" . m)))

(define (config->string options)
  (string-join (map (match-lambda
                      ((option . 'm)
		       (string-append option "=m"))
                      ((option . #t)
		       (string-append option "=y"))
                      ((option . #f)
		       (string-append option "=n")))
                    options)
	       "\n"))
#+END_SRC

Como podemos ver, todas estas son opciones que le añadirán al paquete
de linux-libre a la hora de su construcción. En la configuración del
script modificada de 'make-linux-libre' tenemos:

#+BEGIN_SRC lisp
;; Appending works even when the option wasn't in the
;; file.  The last one prevails if duplicated.
(let ((port (open-file ".config" "a"))
      (extra-configuration ,(config->string extra-options)))
  (display extra-configuration port)
  (close-port port))

(invoke "make" "oldconfig"))))
#+END_SRC

Lo que buscamos es, al no dar una configuración (.config), este es
inexistente, y por lo tanto podemos escribir todas las opciones que
deseemos, aquí está un ejemplo de configuración de el paquete de esta
forma:

#+BEGIN_SRC lisp
(define %macbook41-full-config
  (append %macbook41-config-options
          %filesystems
          %efi-support
          %emulation
          (@@ (gnu packages linux) %default-extra-linux-options)))

(define-public linux-libre-macbook41
  ;; XXX: Access the internal 'make-linux-libre' procedure, which is
  ;; private and unexported, and is liable to change in the future.
  ((@@ (gnu packages linux) make-linux-libre) (@@ (gnu packages linux) %linux-libre-version)
                      (@@ (gnu packages linux) %linux-libre-hash)
                      '("x86_64-linux")
                      #:extra-version "macbook41"
                      #:patches (@@ (gnu packages linux) %linux-libre-5.1-patches)
                      #:extra-options %macbook41-config-options))

#+END_SRC

Verifiquemos esto:

- define :: Primero, se comienza definiendo una variable, la cual
            representará la configuración que se utilizará, está es:
            %macbook41-full-config
- append :: Le añade a la variable %macbook41-full-config lo
            siguiente:
  - %macbook41-config-options :: Contiene opciones de configuración
       que son las que se presentarán a la hora de contruír el paquete.
  - %filesystems :: Añade soporte a sistema de archivos, tales como
                    ext4 o fat, por decir un ejemplo.
  - %efi-support :: Añade soporte para sistemas EFI
  - %emulation :: Añade opciones que nos permiten hacer
                  emulaciones. Específicamente, deja actuar a la
                  computadora de 64 bits, la cual luego definiremos la
                  arquitectura en el paquete, para actuar tambien como
                  si fuera de 32bits.
  - (@@ (gnu packages linux) %default-extra-linux-options))) :: Esto
       dice: necesito que busques el paquete o archivo con el nombre
       de %default-extra-linux-options (el cual es el que utiliza por
       defecto linux-libre).
/@@ se refiere a un objeto privado en un módulo./

Ahora mismo, definimos %macbook41-full-config, que es la unión de un
archivo que contiene opciones normales, más añadiendo support a
sistemas de archivos, a EFI, y a la emulación. Junto con las opciones
que se puedan encontrar dentro de %default-extra-linux-options, osea,
las opciones que ya se utilizan por defecto.

A continuación comenzamos a definir nuestro paquete:

- define-public :: define una variable pública, con el nombre de
                   'linux-libre-macbook41"
- ((@@ (gnu packages linux) make-linux-libre) (@@ (gnu packages ::
- linux) %linux-libre-version) ::  Aquí nos estamos refiriendo a 2
    archivos privador y que no son exportados, dentro de gnu packages
    linux, obtenemos 'make-linux-libre', que es como el paquete es
    construído, y obtenemos de el mismo directorio o lugar la versión
    de linux-libre, mediante obtener la variable
    %linux-libre-version. Luego de esto, tambien nos referimos a la
     variable de linux con la que se obtiene la HASH de el
     paquete. Algo muy importante en Guix, lo que aumenta la
     seguridad.

- '("x86_64-linux") :: Aquí estamos definiendo, en una simple string,
     cuál va a ser la arquitectura que utilizaremos.
- #:extra-version "macbook41" :: Aquí estamos definiendo una version
     'extra', con el nombre de "macbook41".

- #:patches (@@ (gnu packages linux) %linux-libre-5.1-patches) :: Aquí
     estamos utilizando los mismos parches que se utilizan en
     %linux-libre-5.1-patches

- #:extra-options %macbook41-config-options)) :: Esta es la joya y lo
     que hará esta versión del paquete de linux libre diferente, el
     uso de nuestra propia configuración, %macbook41-config-options

Aquí, ya se pudo hacer la modificación del archivo del kernel, pero
pasa algo más... ¿Cómo sabemos que debemos de añadir exactamente para
nuestro sistema?, en el manual que estoy analizando, nos dice que los
mejores lugares que se pueden usar como refencia son: [[https://wiki.gentoo.org/wiki/Handbook:AMD64/Installation/Kernel][El manual de
Gentoo]] y la [[https://www.kernel.org/doc/html/latest/admin-guide/README.html?highlight=localmodconfig][Documentación propia de kernel.]]

Pudo encontrar un comando llamado 'make localmodconfig', el cual es el
que podremos usar para este objetivo.

Primero que nada, primero debemos de instalar el paquete para poder
utilizarlo, usaremos los siguientes comandos:

#+BEGIN_SRC scheme guile

guix build linux-libre --source
tar xf $paquete-de-linux-libre
; Nos situaremos en la carpeta generada al extraer el archivo de linux-libre
touch .config ; Utilizamos este comando, para generar un archivo de configuración
guix environment linux-libre -- make localmodconfig

#+END_SRC
 
Luego de ejecutar el último comando, obtendremos diferentes mensajes,
que estarán demostrando los módulos necesarios para nuestra
computadora, obtendremos este tipo de mensajes:

module pcspkr did not have configs CONFIG_INPUT_PCSPKR

Pueden haber varios de estos mensajes, muchos de hecho, estos son los
que tu computadora necesita. Para cada uno de esos mensajes, se debe
de obtener el CONFIG_XXX_XXX_XXX (todos los que sean mayúsculas y
contengan CONFIG al principio), y se deben de Copiar en el archivo
".config", seguidos de "=m" al final de cada uno. Esto puede ser un
poco tedioso, pero cuando se termine, deberemos de correr nuevamente
'guix environment linux-libre -- make localmodconfig, y revisar si ya
no salen mensajes seguidos de 'module'. Si ya no hay mensajes de este
tipo, significa que se han añadido todos los módulos necesarios en
nuestro archivo .config, el cual podremos nombrar a nuestro gusto.

**** linux-libre-minall

Siguiendo el manual que ya hemos analizado, decidí hacer mi propio
custom kernel. Siguiendo por supuesto los pasos indicados.

Primero se debe de aclarar, que en el manual se definen diferentes
cosas que son necesarias en nuestro archivo para poder hacer nuestra
definición. 

Utilizaremos como ejemplo, la definición de el manual, el cual
modificaremos a nuestro gusto. Es la siguiente:

#+BEGIN_SRC scheme guile

(define-public linux-libre/E2140
  (package
    (inherit linux-libre)
    (native-inputs
     `(("kconfig" ,(local-file "E2140.config"))
      ,@(alist-delete "kconfig"
                      (package-native-inputs linux-libre))))))

#+END_SRC

Como podemos ver, todo aquí ya está definido, solo decidí cambiarle el
nombre a: linux-libre-minall, y el archivo de configuración a
minall.config.

Esto es una definición publica, así como lo es linux-libre-4.9, asi
que lo podríamos llamar como un linux más, por ejemplo, la definición
de linux-libre-4.9 es la siguiente:

#+BEGIN_SRC scheme guile

(define-public linux-libre-4.14
  (make-linux-libre* linux-libre-4.14-version
                     linux-libre-4.14-source
                     '("x86_64-linux" "i686-linux" "armhf-linux")
                     #:configuration-file kernel-config))

#+END_SRC

La cual varía un poco de la que tenemos, sin embargo, las dos
funcionan. Algo que notar, es que las dos definiciones utilizan
variables, las cuales son establecidas o en módulos ya añadidos, o
definidas en la misma definición de linux.

Lo ideal para que nuestro paquete funciones, es añadirlo como la
definición de un nuevo linux, dentro ya de el paquete en la que es
definido linux-libre-4.9, ya que tendremos todas las variables ya
definidas. Esto es posible, simplemente realizando un 'guix edit
linux-libre', y copiando toda la definición obtenida a nuestra nueva
definición.

Para hacer esto, yo utilize emacs junto con emacs-guix, dentro de
emacs, ejecuté: Alt+x, guix-edit y linux-libre. Esto me llevó
directamente a la definición de paquete de linux libre, el cual es
extensa, pero es necesario copiar todo, para no tener errores previos
de 'falta un módulo' o 'variable no definida'.

Luego de copiar toda la definición de linux-libre a nuestra propia
definición, se debe de añadir nuestra definición pública de nuestro
paquete linux-libre-minall, en este caso, quedó de esta manera:

#+BEGIN_SRC scheme guile

(define-public linux-libre-5.2
  (make-linux-libre* linux-libre-5.2-version
                     linux-libre-5.2-source
                     '("x86_64-linux" "i686-linux" "armhf-linux" "aarch64-linux")
                     #:configuration-file kernel-config))

(define-public linux-libre-version         linux-libre-5.2-version)
(define-public linux-libre-pristine-source linux-libre-5.2-pristine-source)
(define-public linux-libre-source          linux-libre-5.2-source)
(define-public linux-libre                 linux-libre-5.2)

(define-public linux-libre-minall
  (package
    (inherit linux-libre)
    (native-inputs
     `(("kconfig" ,(local-file "minall.config"))
      ,@(alist-delete "kconfig"
                      (package-native-inputs linux-libre))))))

(define-public linux-libre-4.19
  (make-linux-libre* linux-libre-4.19-version
                     linux-libre-4.19-source
                     '("x86_64-linux" "i686-linux" "armhf-linux" "aarch64-linux")
                     #:configuration-file kernel-config))


#+END_SRC

El archivo minall.config debe de estar en el mismo directorio que
nuestra defición de paquete.

Si se desea verificar su válidez mediante una instalación, se puede
instalar mediante el comando 'guix package -f linux-libre-minall.scm',

sin embargo, para que sea válido, se debe de de añadir al final de el
archivo dicho nombre para que nos devuelva el paquete. 

#+BEGIN_SRC scheme guile

(...
    (license license:gpl2+))

linux-libre/E2140

#+END_SRC

Ahora podremos instalarlo normalmente, 

Al ejecutar guix package -f linux-libre-minall.scm, comenzará a
instalar el paquete, y nuestro trabajo estará hecho. Luego podremos
añadirlo como un channel o localmente, como ya expliqué anteriormente
en mi manual.

*** Error en la instalación de GuixSystem

La instalación de Guix, no es perfecta, pero contiene lo básico para
instalar Guix System en tu máquina, pero dado a que es una imagen de
instalación muy pequeña, se debe de tomar en cuenta de que es
necesario estar conectado a internet.

Un problema con la instalación de guix, es que al haber un problema,
te da dos opciones, pero las dos te llevan a reinstalar todo de nuevo,
debido a ello, cualquier error de internet, puede reiniciar todo el
instalar, en este caso, si no se desea volver a realizar toda la
instalación, y poner todas las configuraciones, se debe de realizar lo
siguiente:

- Reinicio de usb :: Se debe, primero que nada, reiniciar la
     instalación de GuixSystem, esto es con el motivo de que las
     particiones ya montadas automaticamente se desmonten. La
     instalación de guix monta el sistema en la partición /tmp, y
     nosotros no queremos eso, por ende reiniciaremos la instalación,
     y podremos intentar la instalación manualmente, pero con las
     configuraciones ya establecidas. Luego de ingresar nuevamente a
     la instalación de GuixSystem, se debe de hacer lo siguiente:

- ctrl + alt + f3 :: Utilizamos esta combinacion de teclas, para
     entrar en una terminal a parte, que es la que se utilizará para
     poder hacer la instalación manual, con las configuraciones ya
     establecidas.

- ping -c 3 gnu.org :: Verificar si se tiene el internet, si no, se
     deben tomar acciones, debido a que la instalación necesita de internet.

- lsblk :: Con este comando, podremos verificar cual es nuestra
           partición que contendrá todo el sistema, por ejemplo,
           ¿/dev/sda3 de 400 GB?, es posible que esa sea el sistema.

- mount /dev/sda3 /mnt :: Asumiendo que /dev/sda3 /mnt es el sistema,
     se debe de montar en /mnt preferiblemente, para poder realizar la instalación

- mount /dev/sda1 /mnt/boot :: Si el sistema es EFI, guix debió de
     generar una partición EFI, la cual debe de tener un peso
     aproximado de 500 MB, más o menos, esta se debe de montar en el
     punto de montaje dicho en la configuración que usaremos en
     nuestro sistema, por ejemplo, utilizaré /boot como punto de
     montaje, pero es posible que tu instalación tenga /efi. En ese
     caso, monta la partición en /mnt/efi.

- herd start cow-store /mnt :: Aquí estamos iniciando un servicio el
     cual nos permitirá copiar directamente los archivos en la
     partición, necesario para realizar la instalación.

- guix system init /mnt/etc/config.scm /mnt :: Finalmente, este es el
     comando que utilizaremos para realizar la instalación, antes de
     comenzarla por supuesto, puedes realizar cualquier cambio deseado
     a tu configuración, que esta ubicada en /mnt/etc/config.scm.

Con la utilización de estos comandos, se puede realizar una
instalación manual de GuixSystem, con las mismas configuraciones
ya previstas. Y así evitar tener que realizar de nuevo la instalación
y configuración.

**** Errores

***** Mal montaje de la partición EFI

 Un error que se puede dar en estos casos, es realizar la instalación,
 pero que el sistema no inicie, y entre directamente a 'grub
 rescue'. En estos casos, lo más probable es que se haya montado la
 partición EFI en un lugar incorrecto, y que por ende, ni el sistema ni
 GRUB pueda ser iniciado. En este caso existen diferentes opciones.

****** Reinstalación de el sistema completo

Esto es lo más sencillo que puedes hacer, simplemente entra en el USB
de Guix, ejecuta una terminal con ctrl + alt + f3, y procede a montar
nuevamente todas las particiones, pero montando la partición EFI en
donde le corresponde, inicia el servicioi cow-store, y procede con la
instalación, mediante el comando 'guix system init /mnt/etc/config.scm
/mnt'

A pesar de que es lo más sencillo, estaríamos realizando la
instalación completa de el sistema nuevamente, con esto me refiero, a
que es una opción bastante lenta, debido a que deberemos de esperar la
reinstalación completa.

****** Arreglo de GRUB.

Esta opción es más complicada, pero sin embargo, necesario
entenderla. al estar en 'grub rescue', solo tenemos disponibles muy
pocos comandos:

"En el modo de recuperación, solo los comandos: 'insmod', 'ls', 'set'
y 'unset' están disponibles." [[https://www.gnu.org/software/grub/manual/grub/html_node/Commands.html][GNU GRUB manual]]

Con estos comandos, debemos de arreglar GRUB, para que pueda detectar
en cual es la partición EFI.

- ls :: Utilizamos este comando, para detectar cuales son las
        particiones que detecta grub, por supuesto, obtendremos algo
        similar a (hd0) (hd0,gpt3) (hd0,gpt2) (hd0,gpt1). Estas se
        refieren a las particiones, siendo (hd0,gpl3) /dev/sda3, e
        igual con (hd0,gpl1), que es /dev/sda1, la cual es
        probablemente nuestra partición EFI.
- set :: Al utilizar nuestro comando, nos mostrará variables que
         utiliza GRUB para detectar y buscar lo que necesita, hay una
         variable exacta que es la que utilizaremos, prefix, que es
         donde grub sacará los archivos necesarios para su
         inicialización.
- set prefix=(hd0,gpl1)/boot :: Definimos que donde están los
     archivos, es dentro de la particion /dev/sda1 /boot.
- insmod normal :: Al ejecutar esto, le decimos a grub que 'inicie' nuevamente.
- Entrando al sistema :: Al ya estar en el sistema, tendremos nuestro
     sistema Guix, ahora deberemos de reconfigurar, pero obviamente
     arreglando nuestro problema de montaje. Pero no tardará tanto ya
     que no reinstalará todo el sistema.


****** chmod

Este método no funciono, aún así lo pondré por si acaso debí de hacer
otros comandos que desconozco, y pude de haber funcionado.

Mi idea de utilizar 'chmod', era entrar en nuestro sistema, sin la
necesidad de arreglar GRUB, algo así como el comando 'arch-chroot', el
cual te adentra en el sistema como si hubieras booteado en el. Sin
embargo, fue un intento fallido, quizá con la utilización de otros
comandos aparte de chmod, se pudo de haber entrado al sistema como si
hubieramos booteado en el, y reconfigurar.

*** guix environment

Comando que nos brinda la capacidad de crear entornos reproducibles sin
'contaminar' su entorno de usuario, esto también nos ayuda a poder ver si un
programa funciona correctamente sin todo el entorno, esto es bueno a la hora de
probar el correcto funcionamiento de un programa, o si se desea, incluso revisar
las dependencias de uno, su uso es:

#+BEGIN_SRC bash

guix environment guile

#+END_SRC

Esto creara un entorno en donde estará todo lo necesario para trabajar en guile,
más no usarlo, si se quiere usar, debe de usarse el siguiente comando:

#+BEGIN_SRC bash

guix environment --ad-hoc guile

#+END_SRC

En donde abrirá un entorno en donde no se tendrá todo lo necesario para trabajar
en guile, si no que sera posible usar guile dentro de el entorno.

*** guix package

Comando que nos permite instalar, desinstalar o manejar paquetes, lo
interesante es que, se pueden hacer distintas operaciones
simultáneamente, en vez de una a la vez, como muchos otros
empaquetadores, primero tenemos el comando:

- guix package -i :: Nos permite instalar paquetes, es la que más
     estaremos utilizando, ya que con ella nos estaremos refiriendo a
     un paquete en general.

- guix package -r :: Remover paquetes de el sistema, en el caso de que
     dicho paquete ya no sea necesario.

- guix package -u :: Actualizar el o los paquetes especificados.

- guix package --do-not-upgrade :: Nos permite más control sobre qué
     se actualiza, por ejemplo, utilizando 'guix package -u' comienza
     una actualización de todos los paquetes, sin embargo, si no
     queremos que cierto o ciertos paquetes se actualizen, podemos
     utilizar este comando.

- guix package --roll-back :: Guix nos permite hacer roll-back de los
     diferentes paquetes, y este es realmente lo importante de un
     manejador de paquetes como guix.

*** Realizar un reporte en Guix

Primero que nada, antes de realizar nuestro reporte, es una buena idea
verificar si ya hay un reporte de nuestro mismo problema
(probablemente no), mediante
https://lists.gnu.org/archive/html/bug-guix/, verificado que nuestro
problema no está documentado, deberemos de realizar el reporte.

Realizar un reporte en guix, es bastante sencillo, simplemente al
mandar tu problema a 'bugs-guix@gnu.org', sin embargo, es importante
añadirle ciertos elementos que ayudan aún más a verificar tu problema,
y ayudar a la comunidad.

1. guix describe :: Ayuda a reproducir tu problema con la versión de
                    guix, y el estado de tu sistema.

2. relacionado :: Con esto me refiero a que, por ejemplo, digamos que
                  tu problema tiene que ver con el kernel, sería bueno
                  añadir los resultados de el comando 'uname -r'

3. Lo que esperabas que pasara :: El qué debía de pasar

4. Lo que pasó :: El bug

Teniendo esta estructura, ayuda a que el comando sea resuelto y
documentado, lo que ayuda al aproducción de guix.

** Añadir HTTPS a una página

   Certbot

** Lisp                                                                :Lisp:

 - Lisp :: Cuando hablamos de Lisp, no estamos hablando solo de un
           lenguaje de programación, si no múltiples, se les define,
           una familia, debido a que todos son basados en *Lisp*, entre
           los más famosos son: Clojure, Common Lisp y Scheme, está
           familia de lenguajes de programación son caracterizados por
           el uso de paréntesis más que nada.

*** Scheme                                                           :Scheme:

 - Básico :: Primero que nada, en scheme se utilizan mucho los
             paréntesis, en los que se definiran absolutamente todo,
             tanto variables como funciones. Veamos unos cuantos
             ejemplos:

   - (display (string-append "Hello " "Guix" "\n")) :: Si sabes algo de
	inglés, aquí puedes notar que simplemente estamos uniendo
	strings, para crear la palabra "Hello Guix".

   - Funciones anonimas :: Son muy usadas a la hora de programar, son
	funciones que solo vas a tener que utilizar una vez, por lo que
	no tienes la necesidad de darle un nombre. Estas se definen
	utilizando 'lambda', por ejemplo:

     - (lambda (x) (* x x)) :: Este es un procedimiento normal, pero
          esta función no será guardada, debido a que es anonima, lo
          que hace esta función es multiplicar el número que se le de
          por si mismo, y dar el resultado. Lo podemos usar de esta
          manera: ((lambda (x) (* x x)) 3). De esta manera, la función
          si nos da un resultado, el cual obviamente va a ser 9.

   - Variables :: Las variables se defien por medio de 'define'. por
                  ejemplo, hagamos una prueba de obtener el doble del
                  numero ingresado, pero con variables:

     - (define a 3) :: Ahora, la 'a' se ha convertido una variable, y
                       contiene dentro de si, el valor de 3.

     - (define square (lambda (x) (* x x))) :: Ahora definimos una
          variable 'square' la cual contiene la función anonima con
          lambda que definimos, que nos ayuda a obtener el doble de un número.

     - (square a) :: Al unir estos dos terminos, se puede entender que
                     se va a obtener 9, ya que estamos diciendo, haz la
                     función dentro de square, en a, el cual
                     es 3. Obteniendo al final, el número 9

   - Listas :: Una lista puede ser definida de la siguiente manera:

     - (list 2 a 5 7) :: Esto nos da un resultado de: 2 3 5 7. Ya que
                         como definimos antes con 'define', *a = 3*

   - Comilla :: La comilla *(')* es muy importante en Scheme, ya que
		significa: "No evalues la expresión, por lo tanto, si
		deseamos que algo no sea evaluado, simplemente
		utilizamos la comilla. Por ejemplo:

     - '(list 2 a 5 7) :: Nos da: (list 2 a 5 7), ahora, el a no fue
          modificado, dado que le dijimos a emacs que no lo cambie.

   - Quasiquote :: Te habrás preguntado, y si deseo que se evalúe una
                   expresión, ¿pero que una exactamente no sea
                   evaluada?, para eso sirve la quasiquote, ya que al
                   añadirla, decimos que, como con la comilla, no
                   evalues la expresión, pero al añadir una coma antes
                   de la expresión que deseamos que sea evaluada, se
                   evaluará correctamente. Por ejemplo:

     - `(list 2 ,a 5 7) :: Esto, evaluará la 'a', ya que le dije que lo
          hiciera al añadir la coma, y nos devolverá 3. El cual es su
          valor.

   - Definición de varias variables :: Para definir varias variables,
	se debe de utilizar 'let'. O su hermano 'let*', el cual permite
	la utilización de keywords y argumentos opcionales. (let
        ((x 2) (y 3)) crea dos nuevas variables. Se puede utilizar
        let* para eferirse a ellos nuevamente.
  
*** Guile                                                             :Guile:

 - Guile :: Es un lenguaje de programación patrocinado por el proyecto
            GNU, es una implementación de Scheme, que a su vez esta
            basado en Lisp. Podemos decir que es un lenguaje de
            programación bastante 'maduro', ya que es la base de
            proyectos tan grandes como todo un sistema operativo, Guix. 
 
** Git                                                                  :Git:

- The stupid content tracker :: Sistema de versionamiento utilizado
     universalmente, git nos da una interfaz en la que podremos
     manejar nuestro proyecto de la mejor de las maneras, he incluso
     poder trabajar con diferentes personas a la vez. Incluso si una
     comunidad grande de gente está trabajando en el proyecto, git es
     perfecto para el manejo de proyectos, mediante el sistema de
     versionamiento que nos proporciona.

Es mundialmente usado, por la funcionalidad que da, la cual es muy
buena a la hora de mantener todo el control de un proyecto, ya sea
personal o ya sea un proyecto en el que trabajen muchas personas.

*** Clonar un repositorio por SSH

    Se utiliza el comando:

    #+BEGIN_SRC bash

    git clone ssh://$USUARIO@$IP:$PUERTO/home/$USUARIO/repositorio-git

    #+END_SRC

    Con este simple comando, podremos clonar un repositorio git mediante SSH.

*** Funcionamiento de Git

Utilizé los siguientes comandos para poder aprender un poco el
funcionamiento de git. Iré explicando cada una, y porque la utilizé.

  - mkdir temporal :: Git, al ser un sistema de versionamiento,
                      funciona en el directorio en el que le dices que
                      funcione, o que empieze su trabajo de
                      versionamiento. Debido a esto, cree un nuevo
                      directorio en el que estudiaremos el
                      funcionamiento de Git.
  - cd temporal :: Para iniciar git, nos moveremos dentro de el
                   directorio en la línea de comandos, utilizando cd
                   (change directory)
  - git init :: Este es el comando más básico de git, se encarga de
                decirle a git: 'Comienza tu trabajo'. Al ejecutar este
                comando, se crea una nueva carpeta oculta con el
                nombre de .git, esta carpeta no se debe de tocar, ya
                que contiene todos los funcionamiento de git, no le
                añadiremos ni le quitaremos nada.
  - ls -a :: Ahora, en la carpeta temporal (en la que estamos
             ingresados), solo tenemos una carpeta oculta, la carpeta
             .git, pero no tenemos ningun otro archivo o carpeta
             dentro de este directorio.
  - touch prueba0 :: Utilizamos el comando touch para crear un nuevo
                     archivo vacío, el comando touch, para ser más
                     específico, cambia la fecha de un archivo de
                     acceso o modificación, puedes ver más información
                     con el comando *man touch*, si touch no encuentra
                     el archivo, no cambia ninguna fecha, si no que
                     crea directamente el archivo.
  - ls :: Al utilizar este comando +list+, nos muestra los archivos
          que pueden ser vistos, en este caso, el único archivo que
          tanto esta en el directorio y no es oculto, es que que
          acabamos de crear, prueba0.
  - git status :: Al utilizar este comando, podemos ver que esta
                  haciendo git en ese momento, al simplemente añadir
                  un archivo, podemos ver que ahora, que creamos el
                  archivo *prueba0*, todavía sale, no hay commits
                  todavía, esto se refiere a que no hay ningún cambio
                  a ningún archivo.
  - echo "prueba111" > prueba0 :: Este comando se encarga de añadir la
       string dicha, *"prueba111"*, al archivo.
  - cat prueba0 :: Este comando nos muestra que contiene el archivo,
                   es un comando similar a less, pero sirve con
                   archivos pequeños, ya que solo nos da un output de
                   lo que tiene el archivo, en cambio, un comando como
                   less, sirve para archivos más grandes, ya que te la
                   posibilidad de ver todo el archivo, en cambio,
                   utilizndo cat, es más rápido, pero es mejor para
                   archivos pequeños. En fin, este comando nos
                   muestra la string que acabamos de añadir, *prueba111*.
  - git add prueba0 :: Esto le dice a git, comienza a realizar un
       versionamiento de un archivo, ahora git tiene el archivo en
       versionamiento, cualquier cambio que se realize del archivo,
       git de dará cuenta. Para aquellos archivos que no hayamos
       añadido, no se dará esto.
  - git commit :: Luego de añadir el archivo de a git, realizar un
                  *git commit* es necesario, ya que es decirle a git
                  que actualize toda su información, haciendo que git
                  funcione correctamente en los archivos añadidos.
  - echo "Segunda prueba" > prueba0 :: esto le añade una nueva string
       a el archivo *prueba0*, haciendo un cambio, veremos si git ve
       los cambios.
  - cat prueba0 :: Este comando lo hacemos para ver el cambio en el
                   archivo, y de hecho, ya no está el anterior string
                   de *prueba111*, si no que que ahora esta el nuevo
                   string que añadirmos, *"Segunda prueba"*.
  - git status :: Ahora git capta los cambios, diciendo que hay
                  cambios que debemos de añadir, ya que todavía hay
                  que hacer el proceso de *git add, y git commit*,
                  para hacer que git registre los cambios. Al
                  utilizar este comando, podemos ver que esta
                  pensando git en este momento, verifiquemos que
                  mensajes nos muestran
    - En la rama Master :: Git se maneja por medio de ramas, si por
         ejemplo, tu tienes un proyecto y deseas que el proyecto se
         divida, por ejemplo, si un proyecto de realizar audio quieres
         separarlo para que la base de tu proyecto se encamine en
         reproducción de música, pero que a parte se utilize tambien
         para edición de música profesional, puedes hacerlo, teniendo
         dos 'ramas', una que se enfocara en hacer el reproductor de
         música con la base de tu proyecto, y otro que hará lo mismo,
         pero se encaminará en la edición de audio profesional. Bueno,
         este mensaje nos indica que al solo tener una rama, estamos
         en ella, a rama 'Master', o la principal, como decidas
         llamarla, es la rama en la que estamos ahora, y nuestra única
         rama, por ahora.
    - No hay commits todavía :: Un commit podría definirse como un
         cambio, o más exactamente, una revisión, aquí git
         literalmente esta diciendo: "No hay cambios
         todavía". Obviamente, cuando agreguemos un archivo o un
         cambio +O los dos+, git debe de detectar nuevos +cambios+
         commits.
    - No hay nada para confirmar :: No hay cambios, no hay archivos,
         el directorio esta vacío.

Al utilizar estos comandos y investigarlos uno a uno, se puede ver
cómo es el funcionamiento de git, y así, cumpliendo con nuestra tarea
de aprender de el funcionamiento de este.
    
*** Pérdida de datos de algún archivo

En el caso de que se hayan perdido datos en un archivo, mientras este
tenga control de git, se podrán recuperar con la utilización de los
siguiente comandos: 

- git branch :: Al utilizar este comando, git nos mostrará en que rama
                estamos, es decir, en que parte de el proyecto
                estamos, normalmente nos dirá que estamos en la rama
                'master' u oficial.
- git log :: Este comando le dice a git: "muéstrame todos los cambios
             que he realizado a este archivo". Nos mostrará los
             diferentes commits que he hecho, y podremos volver de
             commit, para poder así sacar los datos que necesitamos
             que se han perdido en el archivo más reciente.
- git checkout "hash" :: Utilizaremos este comando para volver de
     comit, en la parte de "hash", se debe de utilizar la hash única
     que le es dada a cada commit.
- Copia de archivos :: Ahora que volvimos de commit, podemos ver que
     nuestro archivo 'volvio' de versión, ahora ya no tiene los más
     anteriores cambios. Ahora debemos de realizar una copia de el
     archivo, para poder encontrarlo y copiar los datos perdidos de el
     viejo archivo al nuevo.
- git branch :: Nos dirá que estamos en un anterior commit.
- git log :: Nos mostrará todos los commits, y que estamos en uno
             anterior, ahora simplemente debemos de pasarnos a el
             commit más reciente.
- git checkout "hash" :: Utilizando el hash de el commit más reciente,
     ahora notaremos que nuestro archivo volvio a su 'última versión',
     y podemos abrir normalmente los dos archivos, el nuevo y el
     viejo, y añadir lo que se a perdido de el viejo al nuevo.
- git add . :: Ahora que realizamos los cambios, es muy importante
               tenerlo todavía bajo el control de versión.
- git commit :: Tenemos una nueva commit con los cambios más
                recientes, y con los datos perdidos recuperados.

*** Crear un servidor Git

    Crearemos un servidor de Git, en el cual podremos trabajar con
    diferentes personas y acceder a el mediante SSH, o mediante git
    clone. Para ello necesitaremos diferentes elementos:

    - Git :: Servirá para hacer un repositorio Git, Para tener nuestro
             proyecto en control, dado que está orientado en grupos de
             trabajo, también es lo que nos permitirá trabajar en un
             grupo.
    - Servidor :: Una computadora o una laptop, no necesita ser de
                  último modelo, aunque depende de las
                  necesidades. Le configuraremos de tal manera que
                  podremos acceder de el mediante internet.
    - Cliente :: Para probar el funcionamiento de nuestro servidor.

    Primero configuraremos los tres elementos en un servidor local, en
    el probaremos su funcionamiento, luego de ello, lo configuraremos
    para que sea accesible desde internet. Utilizaremos GuixSD en las
    dos estaciones de trabajo. Comenzaremos ingresando en el Servidor,
    y ejecutando:

    #+BEGIN_SRC bash

    $ guix install git emacs ledger-cli emacs-ledger-mode emacs-magit openssh

    /También se pueden instalar con emacs-guix con 'M-x guix p n' /

    #+END_SRC
    
    Aquí estaremos instalando todos los paquetes necesarios de el
    servidor. Openssh con el motivo de probar que nos podemos conectar
    nuestro repositiorio. Terminado el comando, procederemos a
    realizar nuestro repositorio git. Creamos una carpeta:

    #+BEGIN_SRC bash

    mkdir repositorio-git
    cd repositorio-git

    #+END_SRC

    Creada la carpeta y situados en ella, utilizaremos git para crear
    nuestro repositorio:

    #+BEGIN_SRC bash

    git init 
    touch prueba0
    git add .
    git commit

    #+END_SRC

    Con estos cuatro comandos tendremos creado nuestro repositorio,
    git, y en ella tendremos nuestro primero commit con un archivo,
    'prueba0'.

    Estando en una red local, (incluso mejor por LAN), verificaremos
    la IP de nuestro servidor, y la compararemos con la del cliente,
    esto para verificar que las dos estén en la misma
    red. Ejecutaremos el siguiente comando en cada una:

    #+BEGIN_SRC bash

    ip addr
    
    #+END_SRC
    
    Digamos que esto nos muestra que la IP de nuestro servidor es
    '192.168.100.7', y que la de nuestro cliente es '192.168.100.30',
    comparandolas, podremos darnos cuenta que están en la misma red,
    debido a que comienzan con '192.168.100'.

    Ahora sabemos la IP de el servidor, probaremos conectarnos a el
    mediante ssh, instalando openssh también en el cliente, luego
    ejecutando:

    #+BEGIN_SRC bash

    ssh '$USER@192.168.100.7' /usuario es el usuario de el servidor/

    #+END_SRC

    Si nos pide la contraseña y luego de esto podemos conectarnos sin
    problemas, tendremos nuestro servidor listo, ya que podremos ver
    que ya estando en la computadora podemos ver la carpeta
    'repositorio-git', por ende, debemos también clonarla.

    Para poder conectarnos a el servidor mediante internet, lo mejor
    es llamar a tu proveedor de internet, para asignar una IP pública
    a el servidor, probablemente el proveedor le preguntará el IP de
    el dispositivo, el cual puede ser visto por el comando 'ifconfig'

    Digamos que la IP es '183.132.423.321', verifiquemos que podemos
    conectarnos al repositorio.

    #+BEGIN_SRC bash

    /se puede verificar usando ssh/
    ssh '$USER@183.132.423.321'
    /o directamente con git/
    git clone ssh://$USER@183.132.423.321:22/home/$USER/repositorio-git

nn    #+END_SRC
    
    De esta manera verificaremos que podemos ver el archivo, incluso
    mejor con git clone. Algo que tomar en cuenta es el puerto, por lo
    general el puerto asignado a SSH es 22, sin embargo, si se ha
    cambiado, se debe especificar y cambia en puerto en ssh usando -p,
    por ejemplo, suponiendo que el puerto es '2222':
    
    #+BEGIN_SRC bash

    ssh -p '2222' '$USER@183.132.423.321'

    #+END_SRC

    Ya con la prueba completada, tendremos un servidor a el que nos
    podremos conectar por internet, con un repositorio de git.

*** Multiples usuario en Git
Es posible utilizar varios usuarios en git, esto es importante si, por
ejemplo, se está utilizando una misma computadora, algo no muy fácil
de imaginar, pero digamos que en tu trabajo tienen una computadora
servidor que se encarga de el repositorio... Tú, como empleaod de
dicha empresa, debes de ingresar un cigo de mejora a el proyecto, y
git, para esto, te permite identificarte.

En este ejemplo estamos diciendo que la computadora servidor es en la
que todos trabajan a la vez, que utilizan sus recursos, ya que en el
caso de que fuera 'separada', sería más sencillo hacer una
verificación global en tu sistema, por ejemplo:

#+BEGIN_SRC bash

git config --global user.name "Tu nombre"
git config --global user.email "email@email.com"

#+END_SRC

Esto le dira a la git que, en toda la computadora, cuando se utilize
git será con esa identificación, esto debe de ser usado en caso de que
uses una computadora personal para trabajar en otros repositorios git.

En cambio, en el caso de que no te puedas verificar 'globalmente', si
no que varios se tienen que verificar en una computadora, se debe
eliminar el '--global'

#+BEGIN_SRC bash

git config user.name "Nombre, de nuevo."
git config user.email "Tu email, dah."

#+END_SRC

Esto nos permitira identificarnos en ese momento.

** Redes e Internet

   Es importante tener una idea clara de las redes, ya que son lo que
   mueven a el mundo, y lo que lo harán por bastante tiempo. Estas redes
   contienen diferentes elementos, los cuales es bueno estudiarlos en
   individual, debido a que son varios. Estos se manejan por protocolos, los
   cuales son simples reglas que deben de seguir dos nodos para su comunicación.

   Existen diferentes protocolos con diferentes trabajos, el principal de ellos,
   es IP, pero existen protocolos más complicados y que pueden utilizar IP, pero
   no tienen nada de 'similar' con este. 

   Estos protocolos se pueden dividir en dos categorías:

   - Stateless Protocol :: Se refiere a un protocolo que maneja cada
        transferencia individualmente, es bastante 'sencillo' y menos pesado de
        manejar.

   - Stateful Protocol :: Un protocolo más avanzado, en el cual una simple
        transferencia es manejada como un grupo de transferencias más grandes.

*** Internet Protocol (IP)
   
    Es un protocolo, el que se encarga principalmente de darle a cada dispositivo
    un identificador único, con el cual se les podrá ser 'llamados', esto para
    ser específico a la hora de enviar datos.

    Existen diferentes versiones de este protocolo, el más utilizado hoy en día,
    el IPv4 esta hecho de 32 bits y cuatro grupos, o switches. Su rango está
    desde 0.0.0.0 hasta 255.255.255.255.

    Un ejemplo de una dirección de IP, podría ser una local como
    '192.168.100.123'.

	  Debido a que el rango de las IP son límitadas, existen diferentes divisiones
	  de IP, o clases, por cada clase, hay un rango de IP's que son utilizados para
	  un objetivo en concreto.
   
    - Clase A :: 0.0.0.0 - 127.255.255.255
                
                 /El primer valor representa la red, las siguientes, el host/ 

    - Clase B :: 128.0.0.0 - 191.255.255.255

                 /Los dos primeros números, la red, los siguientes, el host/
 
    - Clase C :: 192.0.0.0 - 223.255.255.255

                 /Las tres primeras clases representan la red, la última, el
                 host/
                
    Entre estas, se diferencian por su rango en:             

   
    - IP Privada :: Es aquel rango de IPs que está destinada a ser
                    utilizada en conexiones locales, esté rango de
                    direcciónes es: 192.168.0.0 - 192.168.255.255,
                    10.0.0.0 - 10.255.255.255 y 172.16.0.0 -
                    172.16.255.255. La más común siendo 192.168, si
                    verifica su IP, está probablemente comienze por
                    192.168.

    - IP Pública :: Aquellas destinadas a ser utilizadas públicamente,
                    son todas aquellas que no entren en los rangos
                    anteriormente presentados, estos son más diversos,
o                    por ende, podemos ver que nuestra IP pública puede
                    variar, y no necesariamente debe comenzar por
                    192.168 o similares.

    Para conectarse con un router, dicho dispositivo tiene un IP único, para que
    así no te refieras a otro dispositivo. Al entrar por ejemplo en un navegador
    y referirse a '192.168.1.1' o '192.168.0.1' las cuales son IP's comunes que
    tiene un router, se podrá conectar con el dispositivo.

    Las clases de las IP's son importantes, debido a que declaran en que red
    estas y cuantos dispositivos pueden estar en una red.
    
    Si se quiere revisar si dos dispositivos están en la misma red, debemos de
    conocer la clase de red y verificar que los números en la clase sean los
    mismo.

    Por ejemplo, si un dispositivo con una IP de '192.168.1.12' y otro con
    '192.168.2.13', no están en en la misma red.

    Existen IP's que se utilizan solo en casos especiales, por ejemplo:

    - 0.0.0.0/8 :: Utilizado para la red local

    - 127.0.0.0/8 :: IP's loops

    - 169.254.0.0/16 :: Links locales (APIPA)

    Este protocolo es utilizado en todas las reds, y cada protocolo lo utiliza,
    por lo que me referiré en otros protocolos, podríamos considerar el IP, como
    ser lo más básico de una red.                    

*** Ports (Puertos)

    Son direcciones más específicas, utilizadas para saber a 'dónde' redirigir
    información en una IP (dispositivo). Por ejemplo, una aplicación que
    necesite de información de una red, puede ser configurada para 'escuchar' a
    el puerto '21', cada información que entre por este puerto, sera captada por
    la aplicación.

*** SubnetMask (Mascara Subnet)

    Como hablamos anteriormente, una dirección IP tiene dos elementos, los
    cuales siempre estarán, pero serán algo diferentes depende de la clase de
    IP. Estos son la dirección de red y la dirección de host.

    Dicho esto, una máscara subnet es un número de 32 bits que 'enmascara' la
    dirección IP, y la divide entre dirección de red y de host. Se llama
    (Mascara subnet) debido a que es usado para identificar una dirección de
    red.

    Subnetting un dirección IP de red es por ejemplo, dividir una red de gran
    tamaño en más pequeñas. Todos los hosts en una subnet pueden ver un paquete
    siendo transmitido de cualquier nodo. Debido a esto, una gran red se puede
    ver afectada a la hora de la transmisión de un gran paquete, ya sea por el
    tamaño de este, o por colisiones y retransmisiones.

*** Simple Network Management Protocol (SNMP)

    Protocolo de mantenimiento simple de red es un protocolo muy utilizado para
    el mantenimiento de una red, utiliza los puertos 161 y 162 para manejar
    dispositivos de red. Con este protocolo se puede manejar diferentes
    dispositivos por la red.

    Esto es principalmente bueno para un administrador de red, facilitando su
    trabajo. Pero si una persona no autorizada logra 'entrar' en el protocolo,
    podrá hacer lo mismo que el administrador, es decir, tendrá el control total
    de los dispositivos.
    
    Es un protocolo Stateless, orientado a la transferencia de datagramas. 

    Se maneja con una o varias computadoras administrativas, los cuales
    monitorean y manejan un grupo de computadoras. Cada computadora que sea
    manejada por un administrador, tiene un agente instalado que comunica su
    estado a el administrador, a parte de esto, se utiliza para manejar más
    operaciones administrativas, incluso la modificación y aplicación de nuevas
    configuraciones.

    Los datos que obtiene el agente en cada computadora manejada es guardado en
    una base de datos de una manera jerárgica, llamada 'Managemente Information
    Bases' o MIB. Dichos datos contienen información de un sistema, incluyendo
    su sistema operativo, puertos abiertos, usuarios, aplicaciones instaladas, e
    información extra de el sistema.

*** ¿Qué sucede realmente ante una conexion a un servidor web?

  Cuando se entra a http://www.google.com en un navegador, lo que
  sucede en un nivel alto es:

  1. El navegador extrae el nombre de dominio de la URL, www.google.com

  2. Tu computadora envía un 'pedido DNS' a el servidor DNS
     configurado en la computadora

  3. La computadora intenta realizar una conexión TCP con la
     dirección IP en el puerto 80, el cual es usado para tráfico
     HTTP. Tip: puedes realizar una conneció TCP corriendo 'nc
     216.58.201.228 80 en una terminal.

  4. Si la conexión es aceptada, tu navegador envía un 'Pedido HTTP'
     como este:

     #+BEGIN_SRC 
     
     GET/HTTP/1.1
     Host:www.google.com
     Connection:keep-alive
     Accept:application/html, */*

     #+END_SRC

  5. Luego de enviar este pedido, se esperará una respuesta de el
     servidor, una respuesta como esta:

     #+BEGIN_SRC

     HTTP/1.1 200 OK
     Content-Type: text/html

     <html>
      <head>
       <title>Google.com</title>
      </head>
      <body>
      ...
      </body>
     </html> 
     
     #+END_SRC

  6. Al recibir esto, el navegador analizará y renderizará el archivo
     HTML, CSS y el JavaScript y mostrará dichos resultados como una
     página web, en este caso, de google.

  Ahora, cuando se trabaja específicamente con el navegador, el
  internet y el HTML, como se mencionó antes, se debe de tener un
  'acuerdo' en cómo estos mensajes serán mandados, incluyendo los
  métodos específicos usados para el requerimiento para un 'Host
  request-header' (encabezamiento de petición de anfitrión) para todas
  las peticiones HTTP/1.1, los métodos definidos incluyen: 

  - GET (Obtener) :: Significa obtener cualquier información
                     identificada por la petición 'Uniform Request
                     Identifier (URI)' (Identificador de peticiones
                     uniforme). El término URI puede ser confuso,
                     especialmente dado la referencia de URL arriba,
                     pero esencialmente, para este libro, solo se debe
                     de entender el URL como la dirección de una
                     persona, el cual es un tipo de URI, el cual se
                     puede entender como el nombre de la persona.

  - HEAD (Encabezado)
  - POST (Postea)
  - PUT (Pon)
  - DELETE (Borra)
  - TRACE (Rastrea)
  - CONNECT (Conecta)
  - OPTIONS (Opciones)

*** End-To-End Communication (Comunicación de nodo a nodo)

    Este es el principio más utilizado en las redes, es la manera en la que
    manejamos la transmisión de información. Se refiere a que en la
    transferencia de datos se da de un nodo a otro, de un origen a un destino.

    Los datos deben de transferirse de lugar a lugar, por ejemplo, en una red,
    los datos pueden transferirse de una computadora a otra, utilizando como
    medio un router. La 'routa' de una computadora a otra es el router, sin
    embargo, está es su única función, la información solo 'pasa' por el router,
    dichos datos no se 'quedan' en el router, por lo que los datos solo los
    tienen los 2 nodos.

** Presentación en Org
   
   Para realizar una presentación en org, se debe tomar en cuenta diferentes cosas:
   
   1. Se debe de tener instalado 'Texlive' en tu distribución
   2. Debemos de saber que cada 'arbol' de org será considerado una diapositiva

   El archivo org debe contener lo siguiente al comienzo:

   #+BEGIN_SRC 

   #+options: ':nil *:t -:t ::t 
   #+options: <:t 
   # #+options: H:3 # Este parámetro corrije Outline pero daña títulos y diap
   #+options: \n:nil
   #+options: ^:t
   #+options: arch:headline 
   #+options: author:t
   #+options: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
   #+options: email:t f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
   #+options: tasks:t tex:f timestamp:t title:t toc:f todo:t |:t
   #+title: Título de la presentación
   #+subtitle: Descripción breve de la presentación
   # ¡Al gusto del contador y del gerente!
   #+author: Autor de la presentación
   #+date: Fecha de la presentación
   #+email: E-mail de el autor
   #+language: es
   #+select_tags: export
   #+exclude_tags: noexport
   #+creator: Emacs 26.2 (Org mode 9.2.5)
   #+startup: beamer
   #+LaTeX_CLASS: beamer
   #+LaTeX_CLASS_OPTIONS: [bigger]

   #+END_SRC

   Luego de que se tenga esto, se podrá escribir normalmente en org-mode, cuando ya
   tengas una presentación la cual quieras ver su aspecto. deberemos de hacer un
   org-export.
   
   C-c C-e l P
   
   Esto generará un archivo PDF en Beamer, generando la separación de las
   diapositivas.
   
   Para añadir una imágen, es tan sencillo como añadirla normalmente en org.
   La imágen debe de estar ubicada en el mismo directorio en la que está el archivo
   de org-mode, y se debe de referir a el por medio de:
   
   #+BEGIN_SRC

   [[./imagen.png]]

   #+END_SRC

   De esta manera, nos estaremos refiriendo al archivo, sin importar si es .png o
   .jpg.

** Inicio Remoto
   
   Para poder controlar a una computadora remotamente, lo mejor es
   utilizar ssh, ya que nos permite incluso copiar archivos, usar
   comandos, es basciamente usar la computadora como si estuvieramos en
   ella, para ello es importante:
   
   - Generar un llave publica :: Esto es importante debido a que nos da
	mas seguridad, que simplemente escribir la clave a la hroa de
	entrar a la maquina.
	
	Para ello necesitaremos instalar openssh, con ella, ejecutaremos
	este comando: 
	
	ssh --gen-key
	
	Esto nos permitara hacer una llave privada y una llave publica,
	la llave publica sera como el nombre dice, publica, en cambio pla
	privada no se la deberemos dar a nadie, bajo ninguna
	circunstancia, debido a que es la que utilziaremos para
	desencriptar lo que nos envien.

	Con esto, luego podremos hacer que al esr verificada dicha llave,
	no deberamos de poner la clave para entrar. 
	
	Luego pondremos la llave en la maquina a la que nos queremos
	conectar.
     
   - Copiar archivos mediante ssh :: Para lograr esto, se puede utilizar
	el comando scp, un comando especializado para copiar archivos
	mediante ssh, el uso es: 
	
	scp -P $puerto $archivo-a-copiar
	$destino://a-donde-se-desee-copiar
	
	utilizando este sintaxis, podremos copiar cualquier archivo
	mediante ssh.

** Computación

   - Registros :: Son espacios pequeños de memoria localizados en el mismísimo
                  CPU, donde se puede guardar y manipular dara, en varias
                  arquitecturas, varias de las operaciones solo pueden ser
                  ejecutadas en el contexto de registros, por ejemplo,
                  leer/escribir memoria o aritmética.

                  La mayoría de las operaciones que hace una computadora, se
                  basa en mover datos de la memoria RAM o de el disco duro hacia
                  los registros para ser procesada, y una vez procesada, mostrar
                  esos resultados. Los registros procesan la operación
                  rápidamente, sin embargo, son limitados, depende de la
                  arquitectura, pueden haber entre 6-32 normalmente, pero
                  siempre difieren.

   - Memoria de larga duración :: Datos que son guardados por largos periodos de
        tiempo, por ejemplo, los datos guardados en un Disco Duro no se borrarán
        más que por factores externos. Aquí se almacenan tus archivos y el
        sistema operativo en sí, ya sea Windows, GNU/Linux o Mac.

   - Memoria de corta duración :: Datos que no son almacenados, por ejemplo en
        una RAM, son rápidamente descartados, y tiene una corta duración.

        ¿Por qué sería necesaria una memoria de corta duración?, es una gran
        pregunta, un gran ejemplo de esto es la RAM (Random Access Memory) o
        memoria de acceso aleatorio, su funcionamiento es: Guardar datos de
        aplicaciones abiertas y hacer rápido su acceso.

   Para tratar de explicar, como funcionan estos tres elementos, como ejemplo,
   tomaremos algo sencillo pero que contiene muchas funciones, al abrir un
   simple navegador.

   Al abrir el navegador, suceden diferentes cosas:

   1. Tu sistema operativo entiende la señal, y procede a ejecutar las
      operaciones pedidas.
   2. Al abrirse la aplicación, la RAM comienza a recibir y almacenar datos de
      la aplicación, datos que serán de corta duración y no serán guardados.
   3. Se comienza a usar la aplicación.
   4. La RAM le dá datos a el procesador, los cuales son procesados por
      registros, y los resultados mostrados a el usuario. El disco duro no le dá
      'datos' o procesos directos a el procesador, debido a que, si el disco
      duro haría esto, le daría a el procesador datos de larga duración, lo cual
      sería lento. Debido a esto, la RAM es un método más rápido para que la
      computadora fluya, y que se de un mejor uso de los registro de el
      procesador, lo que sería el procesador en sí, y con por esto, podremos
      usar la aplicación casi a tiempo real.
      
   Debido a que los registros son limitados, y acceder a memoria de largo plazo
   es lento, es utilizada la memoria de corto plazo, o RAM.

   Inventandose un ejemplo con números, digamos que debemos procesar 500MB de
   datos, ya sea de una aplicación o de otra cosa, y que cada registro procesa
   20MB por segundo (de nuevo, es un ejemplo, no son números reales), eso quiere
   decir que si hay 3 procesadores, solo se almacenaran 60MB por segundo.

   Por ende, los MB restantes que no pueden ser procesados, debido a que el
   procesador ya está ocupado con 60MB, son agarradas por la RAM.

   La RAM actúa como una 'sala de espera' para datos a procesar, para que así
   sean de manera rápida alcanzados por el procesador nada más termine con los
   60MB, y así siguiendo hasta terminar los 500MB.

** Hyperbola

   Hyperbola es una distribución de GNU/Linux bastante diferente a
   cualquier distribución, además de ser libre, podemos notar que toma
   de ejemplos lo mejor de las dos distribuciones predominantes,
   Debian y Archlinux, pero modificandola para que no sea ni la una ni
   la otra. A pesar de que se inspira en dichas distribuciones, no se
   basa en ninguna de ella, como ejemplo, no es un Ubuntu que se basa en Debian,
   si no independiente.

   Sus principios estan entre, un balance de simplicidad, elegancia,
   código-correcto y software libre actualizado al momento.

   Esto es interesante ya que, la simplicidad se basa en el principio
   de archlinux, donde tu puedes realizar tu computadora a tu gusto.

   Elegancia se refiere a que cada programa que esté en hyperbola,
   está bien diseñado, por lo que no generará problemas incluso con
   hardware no tan potente. Esto puede ser considerado no muy importante para
   aquellos con buenas computadoras, las cuales no les dan problemas de ningún
   tipo, sin embargo, es muy importante para no 'desperdiciar' nada.

   Un código correcto muestra que cada programa debe de estar bien
   diseñado, con el motivo de mantener estabilidad de este.

   En la página de información de Hyperbola, veremos 'Hyperbola es un
   nuevo paradigma':
   
   Hyperbola = Arch snapshots + Parches de Debian y principio de
   desarrollo + GNU FSDG + Campaña de Init Libre + Privacidad + LTS +
   Stability

   Una parte interesante de esta manera de ver a esta distribución, es
   la privacidad y la 'Campaña de Init Libre'

   La campaña de Init Libre es una lucha para mantener los diferentes
   inits que existen, derivados a systemd, proclamando que systemd
   rompe la compatibilidad y la portabilidad que siempre debe de
   ofrecer GNU/Linux, y que fuerza su uso, lo que ignora el principio
   de GNU/Linux.

   La privacidad, por su lado, quiere decir que el software que esté
   dentro de hyperbola es software libre, ya por ese lado sabemos que
   tendremos la posibilidad de saber que sucede dentro de el programa,
   así estando seguros de que nuestros datos están protegidos, unidos
   con parches de seguridad que se le aplican a hyperbola, para cubrir
   diferentes vulnerabilidades.
   
   Esta distribución planea ir con sus ideas a el final, haciendo
   deciciones que puedan parecer complicadas, pero que luego recobran
   sentido. Por ejemplo, la adopción de Xinerama en lugar de el muy
   utilizado Xorg, El reemplazo de pulseaudio por sndio, todo esto
   puede ser visto en 'https://www.hyperbola.info/todo/'

   Estas deciciones están explicadas rigurosamente en los blogs de
   hyperbola. Están hechas para eliminar aplicaciones que puedan
   causar problemas a futuro, y evitar el 'Software bloat'  el
   'Feature creep', ambos problemas que se dan en programas mal
   diseñados. Dado que el principio de hyperbola es eliminar estos dos
   problemas, requiere hacer este tipo de deciciones.

** Verificar el Hardware en GNU/Linux

   Para verificar todo el hardware en una computadora GNU/Linux, podremos
   utilizar los siguientes comandos:

   #+BEGIN_SRC bash
   
   lspci
   ## Mostrará todos los dispositivos conectados a la computadora
   lspci -v 
   ## Nos mostrará mayor información de cada dispositivo
   lspcu 
   ## Información específica de el CPU
   uname -a
   ## Información básica de el sistema, como el nombre, kernel y memoria RAM
   lsusb 
   ## Dispositivos USB

   #+END_SRC

  
  Fluxion is used to scan nearby networks.


  That's all, it's just a script that helps with the monitor mode or a wireless
  card device.

  There are other ways to set a wireless card on monitor mode, for example:

  sudo iw dev # to check wireless interfaces.

  sudo ip link set IFACE down

  sudo iw IFACE set monitor control

  sudo ip link set IFACE up

  where IFACE replace with the actual name of your wireless interface.

  sudo iw dev

  It may now show your device to be type monitor.

  To return to managed mode, you can make this:

  sudo ip link set IFACE down

  sudo iw IFACE set type managed

  sudo ip link set IFACE up

  You can also use iwconfig for this:

  sudo ifconfig IFACE down

  sudo iwconfig IFACE mode monitor

  sudo ifconfig IFACE up

  and the same for managed mode.

  #Data: Number of captured data packets (if WEP, unique IV count), including
  data boardcast packets.

  #/s: Number of data packets per second mesaure over the last 10 seconds.

  CH: The channel that the AP is using.

  MB: Maximum speed supported by the AP. If MB = 11, it's 802.11b, if MB = 22
  it's 802.11b+ and higher rates are 802.11g. THe dot (after 54 above) indicated
  short preamble is supported. 'e' indicates that the network has QoS (802.11e)
  enables.

  ENC: Stands for encryption, the type of security that it has, normally to
  ever network it will be WPA2, which is widely used.

  OPN = no encryption, "WEP?" = WEP or higher (not enough data to choose between
  WEP and WPA/WPA2), WEP (without the question mark) indicates statis or dynamic
  WEP, and WPA or WPA2 if TKIP or CCMP or MGT is present.
  
  CIPHER: The cipher detected. One of CCMP, WRAP, TKIP, WEP, WEP40, or WEP104.
  Not mandatory, but TKIP is typically used with WPA and CCMP is typically used
  with WPA2. WEP40 is displayed when the key index is greater than 0. The
  standard states that the index can be 0-3 for 40bit and should be 0 for 104
  bit.

  AUTH: Stand for authentication, stands for the method of well, authentication,
  normally, it will be on 'PSK' (pre-shared key for WPA/WPA2) , which means that it needs a password in order
  to authenticate. MGT (WPA/WPA2 using a separate authentication server), SKA
  (shared key for WEP) or OPN (open for WEP).

  ESSID: THe name of the network.

  We'll normally see your target, and we can filter airodump-ng to give us all
  the information we want only about our target with '-d', which shows only
  networks matching the givven BSSID, for example:

  airodump-ng wlan0mon -d E4:BE:ED:D5:FB:D1  

  This will give us all the traffic happening, and some 'STATION' field, which
  is the MAC addressess of the ones that are connected to the network.

  If CIPHER = CCMP:

  CMP (Cryptography)

  Counter MOde Cipher Block Chaining Message Authentication Code Protocool is an
  encryption protocol designed for Wireless LAN products that implements the
  standards of the IEEE 802.11i amendment to the original IEEE.802.11 standard.
  CCMP is an enhanced data cryptographic encapsulation mechanism designed for
  data confidentiality and based upon the Counter Mode iwth CBC-MAC (CCM Mode)
  of the Advanced Encryption Standard (AES) standard.

  CCMP is the standard encryption protocol for use wit hte Wi-Fi Protected
  Access II (WPA2) standard and is much more secure than the Wired Equivalent
  Privacy (WEP) protocol and Temporal Key Integrity Protocool (TKIP) of Wi-Fi
  Protected Access (WPA). CCMP proides the following security sevices:

  Data confidentiality: ensures only authorized parties can access the
  information.

  Authentication: provides proof of genuineness of the user

  Access control in conjunction with layer management.

  Because CCMP is a block cipher mode using a 182-bit key, it is secure against
  attacks to the 2^64 steps of operation. Generic meet-in-the-midle attacks do
  exist and can be used to limit the theoretical strength of the key to 2^n/2
  (where n is the number of bits in the key) operations needed.

  Known attacks:
  
  For cryptographers, a cryptographic "break" is faster than a brute-force
  attack - i.e, performing one tril decryption for each possible key in sequence
  (see Cryptanalysis). A breack can thus include results that are infeasible
  with current technology.

  When looking at the manuel of aircrack-ng it says:

  aircrack-ng - a 802.11 WEP / WPA-PSK key cracker

  There's an option for airdump-ng (-i) that only takes data useful for
  cracking, I'm not sure how to use it though.

  Capturing all the data iwthout the (-i) option, gives files that can be readed
  by wireshark.

  sudo aireplay-ng -0 0 -a E4:BE:ED:D5:FB:D1 -c F8:84:F2:1D:5E:20 -x 150
  wlan0mon

  This disconnect my phone of the network, I had before a message about the
  channel, for example: the AP is on channel 6 but wlan0mon is on 3, this was
  fixed with:

  sudo airmon-ng start wlan0mon 6
  
  -------------------------------------

  sudo airmon-ng

  sudo airmon-ng start wlan0 #wlan0 becomes wlan0 (is now on monitor mode)

  airodump-ng wlan0mon -w

  In the network 'beacons' = ethernet, cable. 

  In the network #Data = WiFi.

  aircrack-ng (file).cap

  Autenticación: network down

  aireplay-ng -0 3 -a (AP) -c (TARGET) -x 150 wlan0mon

  This will make a WPA handshake

  aircrack-ng (file).cap

  This will give us the password in the case the encryption is WEP

  The technique of WPA is:
  
  all .cap files have to be decrypted, so you should always:

  airdecap-ng (file).cap

  This will give us our same file but with dec name.

  Fluxion is a good tool for gathering information about a network.

  For WPA/WPA2 is the most use.

  Bandwidth Eating

  Email servers should be configured to block the bad stuff and allow the good
  stuff to pass to you. You'll have all the hard work of making it happen. All
  email traffic coming and going through a network eats up vital bandwidth. The
  sooner you can detect and inspect email traffic (outbound and epecially
  inbound) on your email server, the less bandwidth is waster. Besides
  preserving bandwidth, the ability to filter bad emails early on will save work
  on CPU server processing.

  ONe technique used is when spam is detected, the server will eliminate it
  after a certain amount of time. THis preents deletoin of email traffic that a
  user might be expecting. Since your email servers are exposed to attacks
  coming from the internet, you should take extra precautins for anyone with
  admin rights. Those who have admin rights should never send or receive email
  while they are logged in with admin privileges In fact, those twith admin
  rights should only se those rights for internal network maintance.

  Email Server Vulnerabilities

  As the name might suggest, an email server is just like any other server. The
  server will have vulnerabilities that can be exploited. The Common
  Vulnerabilities and Enumeratoin database ar cve mitre listed a total of 1043
  email server vulnerabilities in 2012. Many of these issues can be resolved
  through proper server configuration and user privileges. Other issues can only
  be solved by the software manufacture or by being vigilant when shopping for
  server software.

  Email Server Threats:

  Large web email clients like Gmail, Yahoo, and Microfsoft migrated to a new
  cryptographic email signature program called DomainKeys Identified Mail
  (DKIM). DKIM wraps a cryptographic signature around an email that verifies the
  domain name that the message was sent through. DKIM helps filter out spoofed
  messages from legitimate ones. The speciications for DKIM can be found ar
  http://www.dkim.org/.

  The problem involves DKIM test messages. According to US-CERT (United States
  Computr eEmergency Readiness Team), an evil hacker can send a falh that it is
  testing DKIM in messages. Some recipients will "accept DKIM messages in
  testing mode when the messages should be treated as if they were not DKIM
  signed".

  This isn't the first DKIM problem that has attracted CERN's attention. THe
  signature key length used for encryption was vulnerable to craking if the key
  size was too small. DKIM standards set the minimum key size to 1024, with any
  email using a smaller key being rejected by the program. But DKIM operations
  didn't reject smaller key sized emails. Instead, the emails were sent along
  their merry way, fully vulnerable to factor cracking. Once the key was cracked
  ,a hacker could spoof emails or send out malware using that user's email key
  and address..

  DKIM is designed to act as a "trust" verification tool for email. THe system
  uses public-key cryptography, just like PGP does. With proper use, an email
  can be traced back to its original sender through a domain verification
  process. Basically, you are identifying yourself as the sender by your domain
  origin. This should drastically reduce spoofed emails, filter spam, and prove
  that you sent that message. Security folks call this non-repudiation.

  In non-repudiation, the information provider data cannot be changed. THe
  informtioan is not refutable. If you said, "I want to wear a dess," that
  statement cannot be contested. You said it, that is a fac and you will not be
  able to retract that statement. This is important when dealing with contracts,
  legal matter and excuses to your father for not taking out the trash.

  Email for Fun and Profit:

  THanks for the profitable market for corporate espionage, email is a simple
  method to find client contact lists, customer information, meeting noes, netw
  product developments.

  WpsSyns is to enter network by several PINs and MAC addresses. (for android)

  A simple but often missed email security method is scanning of all email
  attachments. Scanning needs to be performed on all data packets, compressed
  files, unknown file types, split files, files that can do the splits, files
  that spit, meta data, files with URLs, and pretty much everything that can be
  donde to a file. This scanning should be focused on inbound traffic but don't
  forget to be suspicious when large attachments are leaving your network.
  Sensitive company information needs to be encrypted, especially if sent by
  email, to anyone inside or outside the network. Oh, by the way, sensitive
  informatino really should never leave the network. If a user is sending
  information outside the network, you might want to keep an eye on thier
  activities.

  Large organizations like the Veteran Affairs Hospitals in the US use dta lossp
  revention (DLP).

  The Key to Success:

  Keyword filtering is a type of application layer filtering (layer 7) that lets
  you block all messages containing particular keywords or phrases that commonly
  appear in spam. Other forms of email filtering include:

  Address Blocking: blocks mail from particular IP addresses, email addresses or
  domain of known spammers.

  Bayesian Filtering: "intelligent" software that can analyze spam messages and
  learn to recognize other messages as spam using heuristics (patterns of
  behavior).

  Blacklisting: List of known spammers' addresses can be shared, so each user
  doesn't have to develop a list from scratch. THese lists are available from
  several providers, and are highly valuable for address blocking.

  Whitelisting: Instead of specifying which senders should be blocked, specifies
  which senders wshould be allowed. Again, these lists are used as part of
  address blocking.

  Greylisting: Temporarily blocks email from unknown sources. Legitimate email

  will be re-transmitted, but spam usaully won't.

  Challenge/Response filtering: replies to email from senders not on a "trusted
  senders" list with a challenge, usually involving solving a task that is easy
  for humans but difficult for automated bots or scripts.

  There are many open-source and for pay applications that can do these kinds of
  filtering, some better and some worse. If you've ever had to deal with there
  PITAs (we'll let you figure out on your own what a PITA is) you'll see them as
  the challenges to clever script writers that they are.

  Esclavizando celulares:

  You need a PC, you have to first, open ports.

  Reread Hacking email.

  Fundamentals of Web security:

  First off, you need to understand that the original idea behing the
  Internet was to link academic organizations with ceratin
  U.S. Department of Defense (DoD) organizations. This meant that the
  Internet (ARPANET) was built on the premise that security wasn't
  needed, since you already had to be either a research university or
  a government entity to connect to the network. The original Internet
  linked a bunch of big computers all over the U.S. to each other so
  security wasn't really an issue, the availability and durability of
  these connections were some of the real concerns.

  This is where the Transport Control Protocol (TCP) was first
  introduced to deliver packets of data from one big computer to
  another big computer far away. Way back then, nobody thought the
  internet would ever get as large as it has today Internet Protocol
  V4 addressing used a 32 bit number sequence which limited addessess
  to a specific amount of addressable devices. Remembering that back
  then there wer only so many universities and defense oganizations
  that would need an IP address. THe idea was to have a connection of
  computer that would provide information to anyone connected to
  it. THe logiv back then was "why would anyone ever want to limit the
  freedom of information exchange?".

  How the Web Really Works

  The web seem pretty simple: you get onto the Internet, open a
  browser, type in a website URL, and the page appears. But the
  devil's in the details, and some of them can hurt you.

  A quick trip to the fine folks who make standards for the web, the
  World Wfide Web Consortium (W3C, at http://www.w3.org), will teah
  you all you want to know about how the web works. Don't miss the
  history of the web at http://www.w3.org/History.html. The problem
  seems to be that definitions and standards might teach you how to be
  sage. But, probably not. The people who want to hurt you don't
  follow standards or laws.

  Reality Check

  1. You open your browser.
     
  2. You type in the Unifor Resource Locator (URL) into the browser's
     address line (the website address, like ISECOM.org; the real
     nerds often call them URI for Uniform Resouce Indicators.

  3. The website URL is saed in the browser's history on the hard
     disk. Yes, there's a record of everywhere you've been, right
     there on your hard drive.

  4. Your computer asks your default Domain Name Server (DNS) to look
     up the IP address of the website. The DNS connects the name
     www.ISECOM.ORG to the IP address of 216.92.116.13. Use
     www.Whois.net to locate detailed information on a web page and
     try a Reverse IP lookup to find the actual numbered address
     instead of the site names. (you can also use ping).

  5. Your computer connects to the website's server, at the IP address
     it was given by the DNS, to TCP port 80 for "http://" websites,
     or TCP port 443 if you go to an "https://" secure web site. If
     you use https:// there are more steps like getting server
     certificates that we won't cover in this example.

  6. Your computer eqests the page you ask for (like History.html), or
     if you specify a folder the web server sends a default page,
     usually index.html. It's the server that decides this default
     file, not your browser.

  7. Your IP address, the web page you are visiting and details about
     your browser are likely to be stored on the web server and/or
     proxy servers in between.

  8. The requested we page is stored in the browsers cache. Yes,
     there's a copy of every page you've visited, right there on your
     hard drive, unless the web server explicitly asks your browser
     not to store it (cache is often disabled for protected web pages
     served through HTTPS, or at least it should be).

  9. Most web pages contain other elements, like pictures, ads, style
     sheets (instructions to your browser on ow the page should be
     displayed), Javascript (little programs, to do checks or make the
     web page look fancy and smooth). All these elements are retrieved
     in a similar manner as typing a URL by yourself.

  10. The browser nearly instantaneously shows you what it has stored
      in your browser's cache. There's a difference between "perceived
      speed" and "actual speed" during your web surfing. This is the
      difference between how fast something is downloaded (actual) and
      how fast your browser and computer can render the page and
      graphics to show them to you (perceived). Remember: Just because
      you didn't see web page elements doesn't mean it didn't end up
      in your browser's cache.

      The Web is a mssive client-server network. Clients are typical
      users who run web browsers to display or capture Internet
      data. Servers are web servers, such a Internet Information
      Server (ISS) on Windows or Apache on Unix/linux. So the browser
      asks for a page, and the web server returns content in the form
      of Hyper Text Markup Language (HTML) pages.

      Rattling the Locks:

      Assume you have put up your own web server to host your blog,
      personal website, photos and whatnot. How could all that
      information be exploited and used against you?.

      Standard HTML pages are transferred using Hyer Text Transfer
      Protocol (HTTP). It's a simple text-based system for connecting
      to a server, making a request and getting an answer. THis means
      that we also can connect easily to a server using command line
      tools like telner and netcat, and get information about what
      software is running on a specific server. Look at what you get
      when you run this simple two-line command:

      netcat isecom.org 80

      HEAD / HTTP/1.0

      HTTP/1.1 200 OK 
      Date: Wed, 29 Deb 2019 23:25:54 GMT
      Server: Apache/2.2.22
      Last-Modified: Tue, 07 Deb 2019 18:41:18 GMT
      ETag: "3dad-4b8641fe2280"
      Accept-Ranges: bytes
      ContentLength: 15789
      Identity: The Institute for Security and Open Methodologies
      P3P: NOt supported at this time
      Connection: close
      Content-Type: text/html

      Every web server and version will return different information
      at this request - an IIS server will return the following:

      netcat www.microsoft.com 80

      HEAD / HTTP/1.0
      
      HTTP/1.1 200 OK
       Connection:close
       Date: .......... GMT
       Server: Microsoft-IIS/6.0
       P3P: CP="ALL IND DSP COR ADM CONo CUR CUSo IVAo IVDo PSA PSD
      TAI TELo OUR SAMo CNT COM INT NAV ONL PHY PRE PUR UNI"
       X-Powered-By: ASP.NET
       X-AspNet-Version: 1.1.4322
       Cache-Control: public, max-age=9057
       Expires: ....... GMT
       Last-Modified: ..... GMT
       Content-Type: text/html
       Content-Lenght: 12934
       
  Getting More Details:
 
  You can take this further and obtain more information by using the
  "OPTIONS" modifier in the HTTP request:

  netcat isecom.org 80
  OPTIONS / HTTP/1.0

  This gives you all of the HTTP commands (or "methods") to which the
  server will respond in a specifig directory (in this case "/", the
  root directory of the web server or "document root").


  Notice that HTTP is completelt 2in the clear"; everyone can see what
  you're browsing for. Consider how this might be changed; look pup
  and learn about "secure searching".

  Doing all of this by hand is rather tedious, and matching it
  manually against a database of known signatures and vulnerabilities
  is more than anyone would want to do. Fortunately for us, some very
  enterprising people have come up with automated solutions like
  nikto.

  Nikto is a Perl script that carries out various tests
  automatically. It runs a scan and provides a detailed report:

  ./nikto.pl -host www.hackerhighSchool.org

  Almos every one of nikto's lines represent a possible vulnerability
  or exploitable code. Using various options you can fine tune nikto
  to do exactly what you need, including stealth scans, mutation and
  cookie detection.

  Mightier and Mitre-er

  Finding a vulnerability is all well and good but what you do with
  that information is a whole different story. Security professionals
  will take the scan results of their own web server and patch,
  update, remove, repair or do whatever they need to do in order to
  close each vulnerability. The nice fols over at Mitre.org operate
  several databases (http://mire.org/work/cibersecurity.html) that
  collect and catalog every known vulnerability you could imagine.

  These databases are given scary names like "Common Weakness
  Enumeration (CWE)" and "Common Vulnerabilities and Exposures (CVE)",
  yet they are faily simple to operate. These systems are a collection
  of other tools and data with a search engine built into each
  database. Each data repository is focused on different aspects of
  hardware, software, services, system configurations, and compliance
  requirements.

  Looking at the results nikto gave us earlier, you can see near the
  bottom of the log are the letters OSVDB followeb by a bunch of
  numbers. OSVDB stands for the Open Source Vulnerability Database
  located at OSVDB.org. In the log results from nikto the numbers
  after OSVDB identify a specific type of vulnerability.

  Browsing Behind Bars: SSL

  When the web started to take off, it wasn't long before everyone
  realized that HTTP in plain text wasn't good for security. The next
  variation was to apply encryption to it. This came in the form of
  Secure Sockets Layer/Transport Layer Security (SSL/TLS, simply
  called SSL), a cryptographic suite encompassing secure ciphers
  implementing 40 to 128 bit (or mode) symmetric key encryption
  methods. A 40 bit key is not as secure than a 128 bit key, and with
  specialized hardware, 40 bit is breakable within a reasonable period
  of time, like during a lunch breack (maybe more). The 128 bit key
  will take much longer: cracking it with only brute force will
  require somewhere between a trillion years and the total age of the
  universe. A streaming cipher suite like RG4 only offers protection
  for about the sqare root of the key space, or half the length of the
  key; so a 128 bit key offers protection of 64 bits, which can be
  cracked on a modern PC in relative short time - think days. One
  thing to remember is that the stronger the key algorithm you use,
  the longer it will take to encrypt and decrypt code. Use encryption
  sparingly or only apply as much strength as you need for web
  surfing.

  Along with SSL, an open source version is available called "OpenSSL"
  and can be found at openssl.org. OpenSSL works alongside Transport
  Layer Security to provide an entire library of cryptographic
  recipes. OpenSSL is a command line tool with many options to work
  with. 

  For known HTTPS attacks there are more complex approaches using
  something called a known cyphertext attack. This involver
  calculating the encryption key by analyzing a large number of
  messages (over a million) to deduce the key. Along with cyphertext,
  you will find multiple attack methods that are discovered everyday.

  Applied SSL

  You shouldn't rush to try and crack 128 bit encryption. Since SSL
  just encrypts standard HTTP traffic, if we set up an SSL tunnel, we
  can query the server just as we did earlier. Creating an SSL tunnel
  is a snap, especially since there are utilities like openssl and
  stunnel made just for the job.

  The Properties of Trust:

  The whole SSL-thing is designed around trust. The browsers contain
  certificates which are really jsut long numbers that serve as
  keys. When you use SSL, the S in HTTPS, the certificate of the
  browser is used to check the certificate of the server and see if
  it's a trustworthy web server. The theory is that if the domain name
  matches the SSL certificate of the server as the domain that we
  visited then it's trustworthy. Of course who says it's trustworthy
  is a whole other problem. IT wouldn't be the first time that a
  criminal infiltrated the certificate authorities and got the keys to
  fake their own server certificates that your browser then tells you
  is trustworthy. In another case, a known skeevy organization that
  was responsible for making spyware paid its way into being a
  certificate authority and added to all the browsers. So trust is a
  big deal on the web. It's another way to attack and it's another way
  that humans badly understand how to protect against it going wrong.

  ISECOM spent time researching trust and discovered 10 main
  properties. You can read more about these properties in the
  OSSTMM. BUt basically, these are 10 things that need to be evaluated
  to have logical (not emotional, gut-feeling) trust:

  - Size :: The number of subjects the trsut extends to.
  - Transparency :: The level of visibility of all operational parts
                    and processes of the subject and its environment.
  - Symmetry of trust :: The vector (direction) of the trust.
  - Subjucation :: The amount of influence of compromise or corruption
                   of the subject.
  - Consistency :: A historical evidence of compromise or corruption
                   of the subject.
  - Integrity :: The amount and timely notice of change within the target.
  - Offsets :: These are offsets of sufficient assurance, the
               compensation paid to the source or punishment for the
               subject when the trust is broken. It's a valued placed
               on the trust with the target.
  - Value of reward :: The financial offset for risk is the amount
       of win ot gain for the source where the potential gain for
       giving trust to the subject is sufficient to offset the risk
       of breach of trust.
  - Components :: This is the number of elements which currently
                  provide resources which the subject relies on either
                  directly or indirectly.
  - Porosity :: This is the amount of separation between the subject
                and the external environment.

  Our parent organization ISECOM pioneered the field of trust
  analysis: the study of reasons we trust - and which reasons are
  actually good ones.

  Employing a Middleman: Proxies

  Using Someone Else's Server

  A proxy server (or just proxy) is a middleman in the HTTP
  transaction process:

  - The client (your browser) sends its request to the proxy
  - The proxy stops and holds your request, then sends its own request
    to the web server
  - THe web server (which doesn't evne know  who you really are)
    responds to the proxy
  - The proxy relays the response back to the client, completing the
    transaction.

  A proxy can be a server on your own network that lets you pass your
  connection through it. This is handy because it gives you some
  protection, since the proxy hides your identity and acts as a
  firewall between you and the rest of the web. But you can also use a
  proxy server that's our on the Internet, which hides you even better
  (on-line you can find many lists of publicly available procies, such
  as http://tols.rosinstrument.com/proxy/). These external proxy
  servers provide critical access to the outside world for people in
  countries that censor or cut off their ISP's connections to the
  Internet.

  But, as you might have figured by now, proxy servers are vulnerable
  to attack themselves, and can become jumping-off points for
  launching attacks on other servers. Not to mention that you may be
  going through one and not even be aware of it - which means it's
  recording everything you do. This is something you especially want
  to consider if you use a free public proxy server. There is
  absolutely no guarantee the owner of that proxy is honest and will
  not use your username/password or credit card details. 

  Using a Local Proxy:

  You can run a proxy server right on your local computer. IT won't
  change your souce IP address (because its address is the same as
  yours), but it can prevent caching and filter our undesirable
  content.

  Privoxy.

  The Onion Router:

  The Onion Router, or TOR, was created to hide your IP address - many
  times over. When you use the TOR network, your traffic gets
  encrypted and passed along through a tangle of routers, and
  eventually emerges .. somewhere. But in theory your traffic can't be
  traced back to you. In theory. In reality, some things - like using
  Flash on Tor - has given unsuspecting users bad surprises.

  Technically, you could set up TOR yourself, which involves some
  interesting configuration. We recommend it for the learning
  experience. However, most of us mere mortals will appreciate the TOR
  Browser, which has all the defaults set for safety, and lets you do
  all that interesting research in a separate browser.

  HTML Programming: A Bried Introduction

  HTML is a set of instructions that explains how information sent
  from a web server (Apache, IIS) is to be displayed in a browser . It
  is the heart of the web. THe World Wide Web Consortium (W3C) is the
  standards organization governing the workings of HTML. 

  HTML can do much more than just display data on a web page. It can
  also provide data entry forms, for server-side processing by a
  higher level language (PEerl, PHP, etc). In a business setting this
  is where HTML is most useful, but in a hacker setting this is where
  HTML is most vulnerable.

  HTML is supposed to be a standard format accross all platforms
  (browsers and operating systems), yet this isn0t always the
  case. Some browsers read the HTML slightly different that other
  browsers just as other OS's wont be compatible with other operating
  systems. Be sure to cross check your HTML code against other types
  of browsers to ensure it is interpreted correctly and doesn't show
  up as a pile of gibberish.

  HTML5:

  The new flavor of HTML, HTML5, brings a lot of security
  improvements. IT doesn0t require flash to stream videos, which is a
  huge leap in terms of preventing unwanted tracking and the endless
  vulnerabilities of Flash.

  On the other hand, it carries a whole stack of new problems with it.

  Cross Domain Messaing or Web Messaging lets HTML5 escape the ugly
  hacks we've used in HTML4 when documents come from more than one
  source. The problem is, this kind of messaging requires a lot of
  trust - and some very secure coding - to ensure nasty things don't
  get into the middle of this process.

  Cross Origin Resource Sharing is when a web server allows its
  resources to be used by a separate domain. Again, this is cool way
  to mash up content from multiple sources - but this level of trust
  just begs to be cracked.

  WebSockets provides asynchronous full duplex communication. That's a
  mouthful, but eseentially it means your browser can bypass the usual
  security measures in return for pure speed.

  Local Storage APIs let web pages store data on your computer. Did
  you know all contemporary browsers include a mini-database called
  SQLite? Now jus wonder: what's stored on your computers database?
  All kinds of interesting things about you, right?

  Scripting Languages:

  old-school coding in languages like C++ meant hours of deep coding,
  then compiling binaries, machine-language instructions that run very
  quickly. If you want raw horsepower, and have a swhole lot of time
  on your hands, this is the world for you.

  THe rest of us wil use scripting languages to write scripts,
  programs written in plain text that are interpreted at runtime by
  binaries (that you don't have to write) underneath. They don't run
  as fast as freestanding binaries, but with the very fast processors
  we have today, you may never notice the difference.

  Scripting languages are great for dynamic web pages, but they also
  create a new avenue of attack for hackers. Most web applications
  vulnerabilities aren't caused by bugs in any particular language,
  but by bad coding and poor web server configuration. For example, if
  a form requests a zip code but the user enters "abcde", the
  application should return them to the form and point out the
  error. THis is called input validation. Here are some of the most
  common scripting platforms today:

  Common Gateway Interface (CGI): This is the granddaddy of scripting
  interfaces, and it's not really a language itself; it's a way to run
  scripts. Perl was one of the most popular scripting languages to
  write CGI programs in the early days, though it's not used much for
  web pages anymoe. Perl is, however, very useful for hackers, and
  many handy tools are written in this language.

  PHP: PHP is a very popular open-source scripting language that runs
  on the server before the page is sent to the user. THe web server
  uses PHP to get data from databases, respond to user choises and
  build a dynamic page with the information the visitor wants. HTML
  displays static ocntent; PHP lets you create pages that give the
  user dynamic, customied content based on their input. Web pages that
  contain PHP scripting usually have a file name ending in ".php".

  Python: Another popular language, Python is a competitor to PHP, and
  does many of the same things. Many web sites use both PHP and Python
  (as well as other languages), including Google.com, Yahoo.com and
  Amazon.com. Python scripts usually have the file extension .py. In
  the world of security, you ought to know as much as you can about at
  least one language. THe flavor used today for security pros is
  Python.

  Active Server Pages (ASP): Web pages that have a .asp or .aspx
  extension (ASPs) are database-driven and dynamically generated just
  like PHP or Python pages. ASP was Microsoft's first server-side
  scripting engine for the web. Its popular successor, ASP.NET, is
  built on the Common Language Runtime (CLR), allowing programmers to
  write code using any supported .NET language, such as: C# VB.NET,
  Jscript.NET, etc. 

  Java Server Pages (JSP): It's a technology that helps software
  developers create dynamically generated web pages. JSP is similar to
  PHP, but it uses the Java programming language. To deploy and run,
  a compatible web server with a servlet contained (such as Apache
  Tomcat) is required.

  Coldfusion and Ruby have their own cult followings, and there are
  dozend less-well-known languages that can do very interesting
  things.

  Javascript: Javascript (which is very much NOT the same thing as
  Java) probably runs on more web pages than any language besides
  HTML. It's different form the scripting languages above, because it
  doesn't run on the server to generate a page. Instead, it runs in
  your browser after the page arrives. THis fives you visual effect
  like fly-out menyus, expandable and collapsible sections of pages
  and "live" interaction with the page. Practically every dynamic page
  uses Javascript somewhere, nd it's the front line of defense for
  validating the information people submit via forms. However, note
  that client-side input validation only is not enough to guarantee
  protection agains attack targetting dynamic web applications
  parameters. One example of ways to abuse client-side scripting is to
  pull up a web page, fill in the form, and capture it with a
  specialized proxy. The proxy lets you rewrite the code in the
  returned page and send it back using bogus values. You could also do
  this by "saving" the web page, editing the code, then sending it
  back using netcat. Or you could simply disable Javascript in your
  browser, using either built-in controls or add-ons.

  Web Vulnerabilities:

  Giving someone what they ask for is simple; selling them something
  is a lot less simple. Online stores, companies selling products,
  bloggers selling ideas and personality, or newspapers selling news -
  all require more than just HTML-encoded tet and pictures. Dynamic
  web sites that market products based on your preferences, show you
  alternatives, recommend other options, up-sell add-ons and make sure
  you pay for what you get require complex software. Ther's no longer
  static web sites, they're web applications. When we say goodbye to
  web sites and hello to web appliciatoins, we enter a whole new world
  of security issues.

  We mentioned earlier "complexity breeds insecurity". Now we are
  going to look at the true meaning behind that mantra. When the
  automobile was first invented, it was nothing more than a wheel, one
  simple wheel. Some folks thought that the wheel was just fine but
  other people wanted to improve on that wheel. These early hackers
  began to add omre wheels together attached with an axle and a
  frame. Others added seats to the frame and still more added a fancy
  horn or installed a horse as the engine. As time went on, this
  simple wheel automobile slowly took shape into a fast multi-horse
  drwan carriage. Luckily, someon added a brake brfore too many other
  got hurt. Today, we have airbags, seat belts, V-8 engines, and
  really great sound systems in our cards without having to smell
  horse dung all the time.

  The Internet's evolutino has progressed in a similar fashion. People
  weren't happy staring at a green isplay screen so they added a color
  monitor. THe old dreary ASCII text became flashing lights and splash
  colors with midi sounds giving way to 3-D surround sound. Each new
  upgrade to the Internet added an ew level complexity, another layer
  of vulnerabilities to consider.

  SQL Injection:

  A SQL Injection isn't so much as an attack agains a web site but
  rather an attack to gain access to databases behind the website. THe
  primary purpose of a SQL Injection is to bypass the webpages. An
  attacker will want to gain either super user privileges to the
  databases associated with the web site or get the web page to dump
  database information into the attacker's hands.

  SQL is the basic building block ofr databases. SQL commands will
  perform whatever task it is asked, including giving up passwords,
  credit card numbers, and so forth. All the attacker is doindg is
  adding rogue SQL code (injecting) to any open form field on a web
  page.

  For example, a web page asks a user if they would like to sign up
  for a monthly newsletter. THe page will have open field fo the user
  to enter their name, email address, and whatever else the web
  builder wants. Each open field allows a user to input text, which is
  then stored in a database. A SQL injection simply requires an
  attacker to input SQL commands into the open fields. If the open
  fields are not protected (parsed) against allowing such commands,
  the attacker can easily type a requesti nto an open field for a
  password list.

  Here is an example of such a SQL request that has been slightly
  sanitized for your protection.
  
  <?php
  $query  = "SELECT '1', concat (uname||'-'||passwd) as name,
  '1971-01-01', '0' from usertable;
                      WHERE size = '$size'";
  $result = odbc_exec($conn, $query);
  
  ?>

  SQL injections are the most popular form of attack vectors. THis
  attack can be rendered useless by correctly filtering SQL escape
  characters in user input fields or building your web site without
  using SQL. Don't forget about the URL field, that's a user input
  field too! Not to mention HTTP headers, cookies and more.

  Buffer Overflows:

  Think of a buffer as a smal cup. THis buffer cup holds a certain
  amount of data and will spill if too much data is added. When the
  buffer cup overflows, because someone ior something tried to add too
  much data, the system behaves strangely. Then a system behaves
  strangely, other weird things can happen. A buffer overflow is an
  attack (or accident) where too much data is forced into a buffer
  that was only built for a certain amount or type of data.

  When we look to the same open fields used in SQL injections, we can
  insert massive amounts of givverish into fields that were designed
  to handle 25 characters. What happens when we add 1 million
  characters th that same field? The web page goes a little crazy and
  can provide an entry point to an attacker.

  Buffer overflows can be avoided by limiting the amount of acceptable
  data to each open field an ensuring rogue code/commands can't be run
  inside these user input fields.

  Cross Site Scripting (XSS):

  Our first two vulnerabilities were direct attacks against a
  server. XSS is a client side vulnerability that exploits a useir's
  trust to gain access into the web servers the client is looking
  at. A good example of this type of attack is when an attacker hitch
  hikes on a users browser while that user is logged in to a security
  site, such as a bank. The attackers preys on the users established
  trust between the user and the bank to gain access.

  The attacker has vaious methods to piggy-back on users
  browsers. Some attackers will establish a Phishing web site or
  created web site that look identical to none the user would vitsit
  Since few people pay any attention to the URL ield in their browser,
  it is fairly common for an attacker to lure a victim into allowing
  malware to be installed in their browser. Email is the preferred
  method to install malware since humans are, well, human.
  
  
  

  

      

  Website Hacking:

  NETSCAN
  

  
  
  
